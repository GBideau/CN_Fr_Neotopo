---
title: "Analyse des créations de communes nouvelles (2012-1er janvier 2020)"
author: "G. Bideau, R. Ysebaert"
date: '`r format(Sys.Date(), "%d %B %Y")`'
bibliography: biblio/biblio.bib
link_citations: true
output:
     html_document:
       toc: true
       theme: united
       css : css/styles.css
editor_options: 
  chunk_output_type: console
---
```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, # Afficher ou non le code R dans le document
                      eval	= TRUE, #	Exécuter ou non le code R à la compilation
                      include	= TRUE, #	Inclure ou non le code R et ses résultats dans le document
                      # results	“hide”/“asis”/“markup”/“hold”	Type de résultats renvoyés par le bloc de code
                      warning = FALSE, # Afficher ou non les avertissements générés par le bloc
                      message = FALSE,
                      cache = TRUE) # Afficher ou non les messages générés par le bloc

# Librairies utilisées
library(sf)
library(cartography)
library(mapsf)
library(corrplot)
library(MTA)
library(readxl)
library(ggplot2)
library(FactoMineR) 
library(factoextra)
library(cluster)
library(reshape)
library(reshape2)
library(flows)
library(sp)
library(knitr)
library(kableExtra)
library(condformat)
library(units)
library(stringr)
```


Les éléments ci-dessous présentent les analyses menées autour de la question des communes nouvelles, dans le cadre d'un article soumis à la revue *L'Espace géographique*.

Les données et le script sont accessibles à l'adresse suivante : <https://nakala.fr/10.34847/nkl.b20d701l>, une version html est plus aisément lisible à cette adresse : <https://gbideau.github.io/CN_2012_2020/>.

NB : Dans ce script, les données sont localisées dans Archives/data_2011-2020. À modifier en fonction de votre localisation des données (celles utilisées sont mises à disposition dans le cadre d'une démarche de science ouverte et reproductible).
La construction de ces données sera précisée dans un *data paper* en cours de rédaction.

# 1 - PRÉSENTATION DES DONNÉES ET CONTEXTUALISATION GÉNÉRALE

## | 1.1 Packages nécessaires


```{r Librairies}
# Librairies utilisées
library(sf)
library(cartography)
library(mapsf)
library(corrplot)
library(MTA)
library(readxl)
library(ggplot2)
library(FactoMineR) 
library(factoextra)
library(cluster)
library(reshape)
library(reshape2)
library(flows)
library(sp)
library(knitr)
library(condformat) # https://cran.r-project.org/web/packages/condformat/vignettes/introduction.html
library(units)
library(stringr)

```


## | 1.2 Import des couches géographiques consolidées et des données

Les données utilisées sont une compilation de données principalement socio-économiques, localisées. La source principale est l'INSEE. Pour plus de détails concernant la préparation des données, cf. le data paper (en cours de soumission).
NB : Ont été exclues des analyses l'Outre-mer et la Corse, espaces non concernés par les communes nouvelles.

Les géométries sont ici importées.

```{r import_layers}

geom2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2011", quiet = TRUE) 
geom2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2020", quiet = TRUE) 
geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE) 
geomCN2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomCN2020", quiet = TRUE)  
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE)

```

Les données socio-économiques qui décrivent les communes en géographies 2011 et 2020 sont ici importées. 
On commence par extraire les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes (`datafus2011`), les  communes nouvelles, avec les géométries au 1er janvier 2020 et caractérisées par les données à la géométrie 2011 agrégées (`dataCN2020`), ainsi que les communes, à la géométrie 2011, qui n'ont pas participé à la création d'une commune nouvelle (`dataNfus2011`)

```{r import_data}

load("Archives/data_2011-2020/refdata.Rdata")
datafus2011 <- subset(df2011, COM_NOUV == "OUI")
dataCN2020 <- subset(df2020, COM_NOUV == "OUI")
dataNfus2011 <- subset(df2011, COM_NOUV == "NON") 

```

## | 1.3 Jointure données / géométries
Dans un certain nombre de cas, il sera utile d'avoir, dans un même objet, les données et les géométries. Les données sont ici jointes aux couches géographiques d'intérêt. 

```{r join_data}

geom2011 <- merge(geom2011, df2011, by = "CODGEO")
geom2020 <- merge(geom2020, df2020, by = "CODGEO_2020")
geomCN2020 <- merge(geomCN2020, dataCN2020, by = "CODGEO_2020")
geomfus2011 <- merge(geomfus2011, datafus2011, by = "CODGEO")

```


## | 1.4 Définition de sous-ensembles pour les tests 
Un certain nombre d'espaces peuvent être étudiés à part : certaines communes nouvelles car elles ont été l'objet d'une enquête qualitative (@bideau2017, @bideau2019), d'autres car elles sont sur des territoires très touchés par les fusions communales.
Ces sous-ensembles sont cartographiés dans la section 1.6.

```{r case_studies1}

testEdC <- subset (geom2011, CODGEO_2020 == "61324" | CODGEO_2020 =="73150" | CODGEO_2020 == "73006")
testEdCSavoie <- subset (geom2011, CODGEO_2020 =="73150" | CODGEO_2020 == "73006")
testNormandie <- subset (geom2011, REG == "23" | REG == "25")
test49 <- subset (geom2011, CODE_DEPT == "49" )
testOuest <- subset (geom2011, REG == "23" | REG == "25"| REG == "53"| REG == "52") # Normandie, Bretagne et Pays-de-la-Loire

```

## | 1.5 Cartographie de localisation

```{r carto_loc, out.width = '100%'}

par(mar=c(0,0,1.2,0))

# Localisation des communes nouvelles
layoutLayer(title = "Communes fusionnantes (2011-2020)", theme = "red.pal",
            author = "G. Bideau, R. Ysebaert, 2021..",
            sources = "Sources : INSEE, IGN, 2020.", extent = dep)
plot(st_geometry(geomfus2011), col = "red", add = TRUE)
plot(st_geometry(dep), col = NA, add = TRUE)

# Nombre de fusions par départements
tmp <- aggregate(list(NUMBER_FUS = datafus2011[,"CODE_DEPT"]),
                 by = list(DEPT = datafus2011$CODE_DEPT),
                 FUN = length)
dep <- merge (dep, tmp, by.x = "CODE_DEPT", by.y = "DEPT", all.x = TRUE)
dep$NUMBER_FUS_rt <- (dep$NUMBER_FUS / sum(dep$NUMBER_FUS, na.rm = TRUE)) * 100 

layoutLayer(title = "Communes fusionnantes (2011-2020)", theme = "red.pal",
            author = "G. Bideau, R. Ysebaert, 2021..",
            sources = "Sources : INSEE, IGN, 2020.", extent = dep)

plot(st_geometry(dep), col = NA, add = TRUE)

propSymbolsChoroLayer(x = dep, var = "NUMBER_FUS", var2 = "NUMBER_FUS_rt",
                      col = carto.pal(pal1 = "blue.pal", n1 = 3,
                                      pal2 = "red.pal", n2 = 3),
                      inches = 0.2, method = "q6",
                      border = "grey50", lwd = 1,
                      legend.var.pos = "topright", 
                      legend.var2.pos = "topleft",
                      legend.var2.values.rnd = 2,
                      legend.var2.title.txt = "Part des fusions (%)",
                      legend.var.title.txt = "Nombre de fusions\ncommunales",
                      legend.var.style = "e",
                      add = TRUE)

# Cartographie des zonages d'études choisis
# Savoie (dont communes enquêtées)
layoutLayer(title = "Communes fusionnantes (2011-2020) : les communes nouvelles (rouge) dont enquêtées (bleu) en Savoie", theme = "red.pal",
            author = "G. Bideau, R. Ysebaert, 2021.",
            sources = "Sources : INSEE, IGN, 2020.", extent = subset(geom2020, CODE_DEPT == "73"))
plot(st_geometry(subset(geom2020, CODE_DEPT == "73")), add = TRUE)
plot(st_geometry(subset(geomCN2020, CODE_DEPT == "73")), col = "red", add = TRUE)
plot(st_geometry(testEdCSavoie), col = "blue", add = TRUE)

# Normandie (dont commune enquêtée)
layoutLayer(title = "Communes fusionnantes (2011-2020) : les communes nouvelles (rouge) dont enquêtée (bleu) en Normandie", theme = "red.pal",
            author = "G. Bideau, R. Ysebaert, 2021.",
            sources = "Sources : INSEE, IGN, 2020.", extent = testNormandie)
plot(st_geometry(testNormandie), add = TRUE)
plot(st_geometry(subset(testNormandie, testNormandie$COM_NOUV == "OUI")), col = "red", add = TRUE)
plot(st_geometry(subset(geomCN2020, CODGEO_2020 == "61324")), col = "blue", border = NA, add = TRUE)

# Maine-et-Loire
layoutLayer(title = "Communes fusionnantes (2011-2020) : les communes nouvelles (rouge) en Maine-et-Loire", theme = "red.pal",
            author = "G. Bideau, R. Ysebaert, 2021.",
            sources = "Sources : INSEE, IGN, 2020.", extent = test49)
plot(st_geometry(test49), add = TRUE)
plot(st_geometry(subset(test49, COM_NOUV == "OUI")), col = "red", add = TRUE)
```


## | 1.6 Analyse multiscalaire de la position des communes nouvelles

Nous souhaitons ici évaluer la position des communes nouvelles dans différents contextes spatiaux vis-à-vis des données sélectionnées.

Pour chaque commune française nous calculons grâce au package `MTA` (@ysebaert2019a) et pour l'ensemble des indicateurs les déviations suivantes. La valeur 100 correspondant à la moyenne du contexte (définis par un rapport entre le numérateur et le dénominateur) :

- Déviation à la moyenne nationale (`devgen`).
- Déviation à la moyenne du département d'appartenance de la commune (`devdep`).
- Déviation à la moyenne de la catégorie d'aire urbaine d'appartenance de la commune (`devcatau`).
- Déviation à la moyenne des communes situées à moins de 10km des communes

Dans chaque cas, nous différencions les communes fusionnantes des autres (respectivement suffixes `fus` ou `Nfus`).

```{r stats_context}

# Transformation en NA des valeurs qui tendent vers l'infini 
geom2011 <- st_set_geometry(geom2011, NULL)
geom2011 <- do.call(data.frame,lapply(geom2011, function(x) replace(x, is.infinite(x),NA)))

# Calculs déviations MTA pour caractériser la position des indicateurs dans différents contextes
ratio <- as.data.frame(read_excel("data-raw/meta.xlsx", sheet = "ratios"))

# Compilation des ratios pour les communes 2011
# Déviation à la moyenne française
for (i in 1:nrow(ratio)){
  geom2011[paste0(ratio[i,"CODE"],"_DEV_GEN")] <-gdev(geom2011, 
                                                      var1 = ratio[i, "Numerator_Code"],
                                                      var2 = ratio[i, "Denominator_Code"],
                                                      type = "rel")
}

# Déviation au département d'appartenance
for (i in 1:nrow(ratio)){
  geom2011[paste0(ratio[i,"CODE"],"_DEV_DEP")] <-tdev(geom2011, 
                                                      var1 = ratio[i, "Numerator_Code"],
                                                      var2 = ratio[i, "Denominator_Code"],
                                                      type = "rel",
                                                      key = "CODE_DEPT")
}

# Déviation à la catégorie d'aire urbaine d'appartenance
for (i in 1:nrow(ratio)){
  geom2011[paste0(ratio[i,"CODE"],"_DEV_CATAU")] <-tdev(geom2011, 
                                                      var1 = ratio[i, "Numerator_Code"],
                                                      var2 = ratio[i, "Denominator_Code"],
                                                      type = "rel",
                                                      key = "CATAEU2010")
}


# Synthèse déviation générale
devgen <- geom2011[,endsWith(colnames(geom2011), "DEV_GEN")]
devgen <- cbind(devgen, geom2011$COM_NOUV)
colnames(devgen)[length(devgen)] <- "COM_NOUV"
# Médiane des communes non fusionnantes
devgenNfus <- devgen[devgen$COM_NOUV == "NON",]
devgenfus <- devgen[devgen$COM_NOUV == "OUI",]
devgenNfus <- as.data.frame(apply(devgenNfus[,1:length(devgenNfus)-1], 2, median, na.rm = TRUE))
devgenfus <- as.data.frame(apply(devgenfus[,1:length(devgenfus)-1], 2, median, na.rm = TRUE))

# Synthèse déviation départements
devdep <- geom2011[,endsWith(colnames(geom2011), "DEV_DEP")]
devdep <- cbind(devdep, geom2011$COM_NOUV)
colnames(devdep)[length(devdep)] <- "COM_NOUV"
# Médiane des communes non fusionnantes
devdepNfus <- devdep[devdep$COM_NOUV == "NON",]
devdepfus <- devdep[devdep$COM_NOUV == "OUI",]
devdepNfus <- as.data.frame(apply(devdepNfus[,1:length(devdepNfus)-1], 2, median, na.rm = TRUE))
devdepfus <- as.data.frame(apply(devdepfus[,1:length(devdepfus)-1], 2, median, na.rm = TRUE))


# Synthèse déviation catégories aires urbaines
devcatau <- geom2011[,endsWith(colnames(geom2011), "DEV_CATAU")]
devcatau <- cbind(devcatau, geom2011$COM_NOUV)
colnames(devcatau)[length(devcatau)] <- "COM_NOUV"
# Médiane des communes non fusionnantes
devcatauNfus <- devcatau[devcatau$COM_NOUV == "NON",]
devcataufus <- devcatau[devcatau$COM_NOUV == "OUI",]
devcatauNfus <- as.data.frame(apply(devcatauNfus[,1:length(devcatauNfus)-1], 2, median, na.rm = TRUE))
devcataufus <- as.data.frame(apply(devcataufus[,1:length(devcataufus)-1], 2, median, na.rm = TRUE))

```


Ces éléments nous permettent de comparer la déviation à la moyenne des communes fusionnantes et des communes inchangées. On peut, d'ailleurs, calculer la différence entre ces éléments.

```{r Tableau comparaison, echo = FALSE}
# Comparaison des valeurs des différents contextes spatiaux

# Calcul des différences entres communes nouvelles et communes inchangées suivant les trois déviations
diffdevgen <- 100 * (devgenfus - devgenNfus) / devgenNfus
diffdevdep <- 100 * (devdepfus - devdepNfus) / devdepNfus
diffdevcatau <- 100 * (devcataufus - devcatauNfus) / devcatauNfus

# r <- ratio$CODE
r <- ratio$DESCRIPTION

tmp <- cbind(r, devgenNfus, devgenfus, devdepNfus, devdepfus, devcatauNfus, devcataufus, diffdevgen, diffdevdep, diffdevcatau)
tmp[2:length(tmp)] <- round(tmp[2:length(tmp)], 2) # On arrondit les variables numériques

colnames(tmp) <- c("Variable", "Déviation à la moyenne française (communes inchangées)",
                   "Déviation à la moyenne française (communes nouvelles)",
                   "Déviation à la moyenne départementale (communes inchangées)",
                   "Déviation à la moyenne départementale (communes nouvelles)",
                   "Déviation aux mêmes catégories d'aires urbaine (communes inchangées)",
                   "Déviation aux mêmes catégories d'aires urbaine (communes nouvelles)",
                   "Différence (%) entre communes nouvelles et communes inchangées concernant la déviation à la moyenne française",
                   "Différence (%) entre communes nouvelles et communes inchangées concernant la déviation à la moyenne départementale",
                   "Différence (%) entre communes nouvelles et communes inchangées concernant la déviation aux mêmes catégories d'aires urbaines"
                   )

# knitr::kable(tmp, row.names = F, digits = 1)

```

Le tableau suivant propose une synthèse des données ainsi construites. Les couleurs sont construites en fonction des minima et maxima des valeurs de chaque partie du tableau (déviations et différences).


```{r Tableau deviations en couleurs, eval  = TRUE, results='asis', echo = FALSE}
mindev <- min(tmp[, 2:7])
maxdev <- max(tmp[, 2:7])
mindiff <- min(tmp[, 8:10])
maxdiff <- max(tmp[, 8:10])


table <- condformat(tmp) %>%
  rule_fill_bar("Déviation à la moyenne française (communes inchangées)", limits = c(mindev, maxdev), low = "darkgreen", high = "darkgreen") %>%
  rule_fill_bar("Déviation à la moyenne française (communes nouvelles)", limits = c(mindev, maxdev), low = "darkgreen", high = "darkgreen") %>%
  rule_fill_bar("Déviation à la moyenne départementale (communes inchangées)", limits = c(mindev, maxdev), low = "darkgreen", high = "darkgreen") %>%
  rule_fill_bar("Déviation à la moyenne départementale (communes nouvelles)", limits = c(mindev, maxdev), low = "darkgreen", high = "darkgreen") %>%
  rule_fill_bar("Déviation aux mêmes catégories d'aires urbaine (communes inchangées)", limits = c(mindev, maxdev), low = "darkgreen", high = "darkgreen") %>%
  rule_fill_bar("Déviation aux mêmes catégories d'aires urbaine (communes nouvelles)", limits = c(mindev, maxdev), low = "darkgreen", high = "darkgreen") %>%
  rule_fill_gradient2("Différence (%) entre communes nouvelles et communes inchangées concernant la déviation à la moyenne française", low = "darkblue", high = "red", limits = c(mindiff, maxdiff)) %>%
  rule_fill_gradient2("Différence (%) entre communes nouvelles et communes inchangées concernant la déviation à la moyenne départementale", low = "darkblue", high = "red", limits = c(mindiff, maxdiff)) %>%
  rule_fill_gradient2("Différence (%) entre communes nouvelles et communes inchangées concernant la déviation aux mêmes catégories d'aires urbaines", low = "darkblue", high = "red", limits = c(mindiff, maxdiff)) %>%
  theme_caption(caption = "Déviations en fonction de l'appartenance à différents ensembles") %>%
  theme_htmlWidget(number_of_entries = nrow(tmp))

print(knit_print(table))

# apply (table[, 2:length(table)], 2, sum)
apply(table[8:10], 2, max)
apply(table[8:10], 2, min)

```

Le premier élément remarquable dans ce tableau est la proximité entre les communes fusionnantes et les communes inchangées concernant la déviation à la moyenne, qu'elle soit française et encore plus départementale ou liée à la catégorie d'aire urbaine.
Cependant, certaines variables sortent du lot et pointent une certaine spécificité des communes nouvelles, que ce soit en comparant à la moyenne française, départementale ou de ZAU : la part des agriculteurs (ou de l'agriculture, sur-représentation), la part des ouvriers (ou de l'industrie, sur-représentation) et la part des actifs travaillant dans leur commune (sous-représentation). Sont également sous-représentés des éléments comme la part de la construction, de l'administration, des professions intermédaires et des cadres.
Cela dessine le profil de communes fusionnantes globalement proche du profil moyen des communes françaises mais ayant comme spécificités des populations plus agricoles, plus ouvrières et, souvent, travaillant davantage hors de leur commune d'habitation.

## | 1.7 Graphique des fusions en fonction du temps
Plusieurs vagues de fusions peuvent être notées depuis la création du statut de communes nouvelles.
Le graphique ci-dessous représente le nombre de communes participant à une fusion. Chaque année est représentée, en commençant par l'année 2011 et en intégrant le 1er janvier de l'année *n* à l'année *n-1* (donc, pour l'année 2019 par exemple, du 2 janvier 2019 au 1er janvier 2020 inclus).

```{r fusions_temps_graph, eval = TRUE}
datafus2011$FusAn <- as.Date(datafus2011$FusAn, tryFormats = "%Y-%m-%d")

datafus2011$FusAnnee <- cut(datafus2011$FusAn, 
                        breaks = as.Date(c("2011-1-1", "2012-1-2", "2013-1-2", "2014-1-2", "2015-1-2", "2016-1-2",
                                           "2017-1-2","2018-1-2", "2019-1-2", "2020-1-2")), 
                        labels = c("2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019")) # Si on utilise l'année (en intégrant le 1er janvier à l'année précédente)

time_serie <- data.frame(table(datafus2011$FusAnnee))

barplot(time_serie$Freq,  xlab = " ", ylab = "Nombre de communes fusionnantes", main = "Nombre de communes fusionnantes en fonction de la date d'effectivité", ylim = c(0, 2000), names.arg = time_serie$Var1)
grid(nx=0, ny = 10, col="gray", lwd=2)



```

## | 1.8 Les communes fusionnantes en fonction de leur taille

La taille est souvent considérée comme le premier facteur menant à une rationalisation de l'échelon communal par fusion. Les municipalités sont effectivement une maille héritée des paroisses, territoires du quotidien religieux, ayant perdu de leur sens dans le cadre des grandes dynamiques démographiques du XIXe et XXe siècle et n'étant plus nécessairement adaptées aux compétences communales. On pourrait alors s'attendre à une proportion de communes fusionnantes bien plus importante parmi les petites communes. On compare ici la proportion des communes en fonction de leur taille, en mettant en parallèle l'ensemble des communes françaises et les communes fusionnantes.

```{r taille des communes}
PopCom <- df2011$P09_POP
PopCom <- cut(PopCom, breaks = c(-1,200,500,1000, 2000, 10000, 2230000))
levels(PopCom)<-c("moins de 200 habitants", "200-500 habitants", "500-1000 habitants",              "1000-5000 habitants", "5000-10000 habitants", "plus de 10000 habitants")
table (PopCom)

tabcont<-table(df2011$FUSION, PopCom)

tab <- round(100*prop.table(tabcont,margin=1),1) # Pourcentages, le total se fait par lignes

kable(tab, row.names = T, digits = 2, caption = "Taille des communes et fusions")

# Proportion sur l'ensemble des communes françaises
round(100* table(PopCom) / length(PopCom),1)
```



```{r Nettoyage espace de travail fin section 1, echo = FALSE}
rm(list=ls())
```



# 2 - LES COMMUNES NOUVELLES AU PRISME DU ZONAGE EN AIRES URBAINES (ZAU)

La présentation caricaturale des communes nouvelles conduirait, du fait de la faible proportion de communes urbaines, à conclure que ce phénomène touche avant tout les espaces ruraux. Cette présentation serait trompeuse et on souhaite s'arrêter ici sur une analyse plus précise de la répartition des communes nouvelles en fonction du zonage urbain.

## | 2.0 Préparation des données

```{r Prep data section 2, eval = TRUE}
load("Archives/data_2011-2020/refdata.Rdata")
datafus2011 <- subset(df2011, COM_NOUV == "OUI") # Désigne les données concernant les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes
dataNfus2011 <- subset(df2011, COM_NOUV == "NON") # Les communes, à la géométrie 2011, qui n'ont pas participé à la création d'une commune nouvelle
datafus2011 <- datafus2011[, c("CODGEO", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "CATAEU2010", "FusPhas")]
dataNfus2011 <- dataNfus2011 [, c("CODGEO", "CODGEO_2020", "LIBGEO", "CODGEO", "CATAEU2010")]
c("CATAEU2010", "ZAU_POL", "ZAU_RUR", "ZAU_MAR_SP", "ZAU_MAR", "ZAU_PERI", "ZAU_AU")
```


## | 2.1 Les communes nouvelles en fonction des ZAU
À partir des données INSEE précisant le zonage en aire urbaine de chaque commune (`CATAEU2010`), nous pouvons observer le profil des communes fusionnantes en le comparant à celui des communes inchangées.

```{r Les communes nouvelles en fonction des ZAU, out.width = '100%'}

ZAU_non <- data.frame(dataNfus2011$CATAEU2010)
ZAU_oui <- data.frame(datafus2011$CATAEU2010)

ZAU_non$Fusion <- "Communes inchangées"
ZAU_oui$Fusion <- "Communes fusionnantes"

colnames(ZAU_non)[1] <- "CATAEU2010"
colnames(ZAU_oui)[1] <- "CATAEU2010"

ZAU <- rbind(ZAU_oui, ZAU_non)

ZAU <- table(ZAU$Fusion, ZAU$CATAEU2010)

prop <- prop.table(ZAU, 1) * 100

barplot(prop, main= NULL,
        xlab = "Catégories d'aire urbaine",
        ylab = "Part du total des communes (%)",
        las = 2,
        border = NA,
        col=c("#ff87a9","#f7d358"),
        beside = TRUE)

legend(x="topright", legend = rownames(prop) , cex=0.8,
       fill=c("#ff87a9","#f7d358"),bty="n")     


# Chi2
tab.chi2 <- chisq.test(ZAU)
tab.chi2 

tab.chi2$observed
tab.chi2$expected
tab.chi2$residuals

mosaicplot(ZAU, shade = TRUE,  cex=0.6, main = NULL, xlab = "Communes fusionnantes",
           ylab = "Communes inchangées")
```

Ces éléments permettent de se rendre compte que les profils des communes fusionnantes et des communes inchangées sont relativement proches. Les écarts les plus importants se situent aux extrêmes : ainsi, les communes fusionnantes sont marquées par une plus faible représentation des communes centres de grands ou moyens pôles dans les communes nouvelles et une sur-représentation des communes multipolarisées ou hors influence des pôles. Le test de Chi² réalisé permet de rejeter l'hypothèse d'indépendance des deux variables.


## | 2.2. Chaque commune nouvelle est-elle composée d'un seul type de ZAU ?

```{r Composition des CN en fonction des ZAU}

# Définition d'un tableau comportant le nombre de communes fusionnantes par commune nouvelle
count_CN <- plyr::count(datafus2011, "CODGEO_2020")

mesCommunes <- count_CN$CODGEO_2020

df <- datafus2011

results <- data.frame()
for (i in mesCommunes) { # Pour chaque identifiant de commune nouvelle, 
  toto <- subset (df, CODGEO_2020 == i ) # Ne garder que les communes fusionnantes y ayant participé
  a <- table(toto$CATAEU2010) # Relever les ZAU des communes fusionnantes
  results <- rbind(results,a) # Combiner les résultats, par lignes
 # rm(a) # Supprimer "a"
}
x <- c("111","112","120","211","212","221","222","300","400") # On renomme les colonnes
colnames(results) <- x
count_CN <- cbind(count_CN, results)

# On identifie la variable la plus fréquente
count_CN$max <- apply(count_CN[, 3:11], 1, function(x) max(x, na.rm = TRUE))
# Quel est le code ZAU revenant le plus fréquemment dans une CN
count_CN$ZAUmaj2 <- colnames(count_CN[, 3:11])[apply(count_CN[, 3:11], 1, which.max)]
# On note si une CN a des communes fusionnantes avec un ZAU identique
count_CN$ZAUident <- ifelse(count_CN$max == count_CN$freq, TRUE, FALSE)
summary(count_CN$ZAUident)

rm(results)
# On extrait les CN ayant des communes fusionnante avec un ZAU identique
CNIdent <- subset(count_CN, ZAUident==TRUE)
CNIdent <- merge(CNIdent, datafus2011[, c("CODGEO", "CATAEU2010")], by.x = "CODGEO_2020", by.y = "CODGEO", all.x = TRUE)

tabcont<-summary(CNIdent$CATAEU2010)
round(100*prop.table(tabcont,margin=),1) # Pourcentages de chaque ZAU chez les communes nouvelles
tabcont2<- summary(datafus2011$CATAEU2010)
round(100*prop.table(tabcont2,margin=),1) # Pourcentages de chaque ZAU chez les communes françaises


```

On peut donc en conclure qu'une large majorité des communes nouvelles sont, du point de vue du ZAU, composées de communes au profil homogène.

```{r Nettoyage espace de travail fin section 2, echo = FALSE}
rm(list=ls())
```

# 3 - PROXIMITÉS STATISTIQUES 


## | 3.0 Préparation des données

```{r Prep data section 3, eval = TRUE}
geom2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2011", quiet = TRUE) # Les communes selon la géographie en vigueur au 1er janvier 2011.
geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE) # Les  communes qui ont participé à la création de communes nouvelles (appelées communes fusionnantes).
geomCN2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomCN2020", quiet = TRUE) # Les  communes nouvelles, avec les géométries au 1er janvier 2020 et caractérisées par les données à la géométrie 2011 agrégées.
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE) # Départements


# Import et sélection des données
load("Archives/data_2011-2020/refdata.Rdata")

df2011 <- df2011 [, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "CATAEU2010", "FusPhas", "COM_NOUV", "FUSION", "P09_RETR1564_RT", "C09_ACT1564_Agr_RT", "C09_ACT1564_ArtCom_RT", "C09_ACT1564_Cadr_RT", "C09_ACT1564_ProfInt_RT", "C09_ACT1564_Empl_RT","C09_ACT1564_Ouvr_RT", "P09_POP0014Y_RT", "P09_POP1529Y_RT", "P09_POP3044Y_RT", "P09_POP4559Y_RT", "P09_POP6074Y_RT", "P09_POP75PY_RT", "P11_POT_FIN", "P09_POP", "REG")]
df2020 <- df2020 [, c("LIBGEO_2020", "CODGEO_2020", "CODGEO", "CATAEU2010", "FusPhas", "COM_NOUV", "FUSION", "P09_RETR1564_RT", "C09_ACT1564_Agr_RT", "C09_ACT1564_ArtCom_RT", "C09_ACT1564_Cadr_RT", "C09_ACT1564_ProfInt_RT", "C09_ACT1564_Empl_RT","C09_ACT1564_Ouvr_RT", "P09_POP0014Y_RT", "P09_POP1529Y_RT", "P09_POP3044Y_RT", "P09_POP4559Y_RT", "P09_POP6074Y_RT", "P09_POP75PY_RT", "P11_POT_FIN", "P09_POP", "REG")]



datafus2011 <- subset(df2011, COM_NOUV == "OUI") # Désigne les données concernant les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes
dataCN2020 <- subset(df2020, COM_NOUV == "OUI") # Les  communes nouvelles, avec les géométries au 1er janvier 2020 et caractérisées par les données à la géométrie 2011 agrégées.

# Appariement des données
geom2011 <- merge(geom2011, df2011, by = "CODGEO")
geomfus2011 <- merge(geomfus2011, datafus2011, by = "CODGEO")
geomCN2020 <- merge(geomCN2020, dataCN2020, by = "CODGEO_2020")

```



## | 3.1 Proximité statististique (distance euclidienne) entre communes fusionnantes

On calcule ici la proximité statistique qui existe, ou non, entre communes ayant fusionné au sein d'un même ensemble. À partir des données socioéconomiques, nous pouvons observer la proximité entre des communes (`LIBGEO_2011`) de même appartenance communale (`LIBGEO_2020`).

```{r Proxim statistique, out.width = '100%'}

tmp <- datafus2011 [, c("CODGEO_2020", "P09_RETR1564_RT", "C09_ACT1564_Agr_RT", "C09_ACT1564_ArtCom_RT", "C09_ACT1564_Cadr_RT", "C09_ACT1564_ProfInt_RT", "C09_ACT1564_Empl_RT","C09_ACT1564_Ouvr_RT", "P09_POP0014Y_RT", "P09_POP1529Y_RT", "P09_POP3044Y_RT", "P09_POP4559Y_RT", "P09_POP6074Y_RT", "P09_POP75PY_RT")]
# tmp <- datafus2011 [, c("P09_CHOM1564_RT", "P09_ETUD1564_RT", "P09_RETR1564_RT", "C09_ACT1564_Agr_RT", "C09_ACT1564_ArtCom_RT", "C09_ACT1564_Cadr_RT", "C09_ACT1564_ProfInt_RT", "C09_ACT1564_Empl_RT", "C09_ACT1564_Ouvr_RT", "P09_POP0014Y_RT", "P09_POP1529Y_RT", "P09_POP3044Y_RT", "P09_POP4559Y_RT", "P09_POP6074Y_RT", "C09_ACTOCC_OUT_RT", "COM_NOUV", "CODGEO_2020")]
tmp <- na.omit(tmp)

d <- by(tmp, tmp$CODGEO_2020, function(x)dist(x, method = "euclidean"))
df <- as.data.frame(sapply(d,mean))

df$CODGEO_2020 <- row.names(df)
colnames(df)[1] <- "dist_CN"

geomCN2020  <- merge(geomCN2020 , df, by.x = "CODGEO_2020", all.x = TRUE)

# Export des données sur la distance euclidienne
st_write(obj = df, dsn = "Archives/sorties_2011-2020/disteucl.gpkg", layer = "disteucl", delete_layer = TRUE, quiet = TRUE)

# Cartographie
par(mar=c(0,0,1.2,0))

plot(st_geometry(dep), col = NA)

choroLayer(x = geomCN2020 , var = "dist_CN",
           method = "quantile", nclass = 6,
           col = carto.pal(pal1 = "blue.pal", pal2 = "red.pal", n1 = 3, n2 = 3),
           border = NA,
           legend.pos = "topleft", legend.values.rnd = 2,
           legend.title.txt = "Distance statistique (euclidienne) moyenne par groupe de communes nouvelles",
           add = TRUE)

layoutLayer(title = "Distance euclidienne intra-groupe", theme = "red.pal",
            author = "G. Bideau, R. Ysebaert, 2021.",
            sources = "Sources : INSEE, IGN, 2020\nIndicateurs : P09_RETR1564_RT, C09_ACT1564_Agr_RT, C09_ACT1564_ArtCom_RT, C09_ACT1564_Cadr_RT, C09_ACT1564_ProfInt_RT, C09_ACT1564_Empl_RT,C09_ACT1564_Ouvr_RT, P09_POP0014Y_RT, P09_POP1529Y_RT, P09_POP3044Y_RT, P09_POP4559Y_RT, P09_POP6074Y_RT, P09_POP75PY_RT")


# Zoom sur la Normandie 
# norm <- subset (geomCN2020 , REG == "23" | REG == "25") # Si anciennes régions
norm <- subset (geomCN2020 , REG == "28")
bb <- st_bbox(norm)
bbnorm <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
norm <- norm[!is.na(norm$LIBGEO),]
plot(st_geometry(bbnorm), col = NA, border = NA)

plot(st_geometry(dep), add = TRUE)

propSymbolsChoroLayer(x = norm, var = "P09_POP", var2 = "dist_CN",
                      method = "quantile", nclass = 6,
                      col = carto.pal(pal1 = "blue.pal", pal2 = "red.pal", n1 = 3, n2 = 3),
                      border = NA,
                      legend.var.pos = "left",
                      legend.title.cex = 0.7,
                      legend.var.title.txt = "Population totale",
                      legend.var2.pos = "topleft", legend.var2.values.rnd = 2,
                      legend.var2.title.txt = "Distance statistique (euclidienne)\nmoyenne par groupe\nde communes nouvelles",
                      add = TRUE)

layoutLayer(title = "Distance euclidienne intra-groupe",
            author = "G. Bideau, R. Ysebaert, 2021..",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            sources = "Sources : INSEE, IGN, 2020.\nIndicateurs : ACT_AGR_RT, ACT_ART_RT,
ACT_INT_RT, ACT_EMP_RT, ACT_OUV_RT, ACT_RET_RT, 
ACT_NON_RT, POT_FIN, POP_0010Y_RT, POP_1117Y_RT, 
POP_2539Y_RT,  POP_4054Y_RT, POP_5564Y_RT,
POP_6579Y_RT, POP_80PY_RT")

# To do : Jouer peut être cette distance avec moins de variables pour mieux contrôler ce qui se passe : par variables démo, éco, emploi et voir si les natures des distances sont les mêmes
```

Une grande diversité de situations est visible concernant cette distance euclidienne, mais avec des tropismes régionaux intéressants. En particulier, en Bretagne et Pays-de-la-Loire, ce sont des communes nouvelles plutôt marquées par une faible distance euclidienne qui sont majoritaires. C'est le cas aussi, bien que moins nettement, en Savoie ou en Alsace. Certaines régions sont davantage marquées par des communes nouvelles davantage hétérogènes : les Pyrénées, le sud du Massif Central. Enfin, dans les régions très marquées par les fusions, on peut noter le cas de la Normandie, où les situations sont très variables.



```{r Nettoyage espace de travail fin section 3, echo = FALSE}
rm(list=ls())
```

# 4 - APPROCHE MULTISCALAIRE DES INÉGALITÉS DE RESSOURCE DES COMMUNES NOUVELLES 

## | 4.1 Préparation des données et calcul des déviations



À partir du package MTA, on regarde la proximité statistique des communes nouvelles
Cf. https://cran.r-project.org/web/packages/MTA/vignettes/MTA_Scenario.html (@ysebaert2019).
On trouvera une vignette présentant le déroulé logique et la description précise des différentes fonctions du package [ici](https://rysebaert.gitpages.huma-num.fr/mta_rzine/).

Cette analyse porte ici sur le potentiel financier des communes. 

On importe le ratio d'intérêt (potentiel financier par habitant par exemple), défini par un numérateur (potentiel financier) et un dénominateur (population municipale). On réalise cette extraction pour l'ensemble des communes françaises, afin de caractériser la position des communes nouvelles sur cet indicateur au regard de la moyenne nationale ; ainsi que juste pour les communes nouvelles, afin de pouvoir caractériser les inégalités existant au sein de celles-ci. 

```{r import_data_pour_MTA}

# Import des géométries
geom2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2011", quiet = TRUE)
geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE)
geomCN2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomCN2020", quiet = TRUE)
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE)

# Import des données d'intérêt : on ne garde que les variables utiles et
# celles qui peuvent être d'intérêt pour définir des appartenances
load("Archives/data_2011-2020/refdata.Rdata")

df2011 <- df2011 [, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "CATAEU2010", 
                      "P11_POT_FIN", "P11_Rev_Fisc", "P09_ACT1564", "P09_CHOM1564", "P09_POP", "REG", "CODE_DEPT","ChefLieu", "FUSION")]


# Jointures
geom2011 <- merge(geom2011, df2011, by = "CODGEO", all.x = TRUE)
geomfus2011 <- merge(geomfus2011, df2011, by = "CODGEO", all.x = TRUE)
geomCN2020 <- merge(geomCN2020, df2020, by = "CODGEO_2020", all.x = TRUE)

```

Grâce au package `MTA`, on calcule pour cet indicateur plusieurs déviations, dont la moyenne est exprimée en indice 100 :
- Écart général à la moyenne française et à celle des communes nouvelles. 
- Écart aux communes de même catégorie de ZAU, pour l'ensemble des communes françaises et uniquement les communes nouvelles. 

```{r selec_var_dev, eval = TRUE}
num <- "P11_POT_FIN"
nomnum <- "Potentiel financier"
denom <- "P09_POP"
# 
# num <-  "P11_Rev_Fisc"
# denom <- "P09_POP"
# geom2011 <- na.omit(geom2011)
# df2011 <- na.omit(df2011)
# 
num <-  "P09_CHOM1564"
nomnum <- "Taux de chômage des 15-64 ans\n"
denom <- "P09_ACT1564"
```



```{r ecart_global, eval = TRUE}
# Calcul des déviations générales
geom2011$gdevfr <- gdev(x = geom2011,  var1 = num, var2 = denom, type = "rel")

# Calcul des déviations à la ZAU de même appartenance
geom2011$mdevfr <- tdev(x = geom2011, var1 = num, var2 = denom, type = "rel",
                        key = "CATAEU2010")


# On ne s'intéresse qu'aux communes fusionnantes
df <- st_set_geometry(geom2011, NULL)
geomfus2011 <- merge(geomfus2011, df[,c("CODGEO", "gdevfr", "mdevfr")],
                     by = "CODGEO", all.x = TRUE)

```


## | 4.2 Position des communes fusionnantes au regard de la moyenne française et de leur ZAU d'appartenance

On s'intéresse ici à caractériser globalement les communes fusionnantes au regard d'une variable (potentiel financier ou taux de chômage). Grâce au package MTA, nous commençons par réaliser deux représentations cartographiques. La première pour évaluer la position des communes nouvelles au regard de l'ensemble de ces communes. 

La seconde pour observer uniquement la situation des communes fusionnantes entre  elles. Ceci afin de mettre en évidence quelles sont celles qui disposent du plus de potentiel financier entre elles. 



```{r carto_dev_gen_terr, eval = TRUE, out.width= '100%'}

# Visualisation des déviations générales et territoriales
cols <- carto.pal(pal1 = "blue.pal", n1 = 3, pal2 = "wine.pal", n2 = 3)

# plot a choropleth map of the relative global deviation
par(mfrow = c(1,2), mar = c(0,0,1.2,0))
choroLayer(x = geomfus2011, var = "gdevfr", legend.pos = "topleft",
           legend.title.txt = "Déviation relative\n(100 = moyenne française)",
           legend.title.cex = 0.7,
           breaks = c(min(geomfus2011$gdevfr, na.rm = TRUE),
                      75, 90, 100, 111, 133,
                      max(geomfus2011$gdevfr, na.rm = TRUE)), 
           border = NA, col = cols)

plot(st_geometry(dep), col = NA, add = TRUE)

layoutLayer(#title = "Potentiel financier\nécart à la moyenne française",
            title = paste0(nomnum, "\nécart à la moyenne française"),
            sources = "INSEE, 2009-2011", author = "G. Bideau, R. Ysebaert, 2021.",
            scale = FALSE, tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black")
dev.print(device = svg, file = paste0("figures/Dev ", num, " ecart_Fr", ".svg"))

choroLayer(x = geomfus2011, var = "mdevfr", legend.pos = "topleft",
           legend.title.txt = "Déviation relative\n(100 = moyenne de la catégorie de ZAU d'appartenance)",
           legend.title.cex = 0.7,
           breaks = c(min(geomfus2011$mdevfr, na.rm = TRUE),
                      75, 90, 100, 111, 133,
                      max(geomfus2011$mdevfr, na.rm = TRUE)), 
           border = NA, col = cols)

plot(st_geometry(dep), col = NA, add = TRUE)

layoutLayer(#title = "Potentiel financier\nÉcart à la moyenne de la ZAU d'appartenance",
            title = paste0(nomnum, "\nécart à la moyenne française"),
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black")

dev.print(device = svg, file = paste0("figures/Dev ", num, " ecart_ZAU", ".svg"))

```




La fonction `bidev` présente la synthèse du positionnement des communes nouvelles sur ces deux déviations. Ce graphique reprend une des fonctionnalités d'[HyperAtlas](http://hypercarte.imag.fr/hyperatlas.html), le logiciel de référence historique qui permet l'analyse des inégalités territoriales. Cette fonction est désormais implémentée dans le package `MTA`.    

Pour synthétiser la positionnement des communes nouvelles sur deux déviations, on commence par les situer dans un repère orthonormé : les communes représentées en rouge sont celles dont la moyenne du potentiel financier par habitant se situe au dessus de la moyenne française et de leur ZAU d'appartenance ; celles représentées en bleu en dessous de la moyenne pour les deux contextes ; et en jaune et vert dans des situations contradictoires en fonction des contextes spatiaux. 

On s'intéresse aussi ici à l'éloignement statistique au regard des valeurs moyennes : plus la valeur des communes se situe loin des valeurs moyennes des contextes, plus la tonalité de couleur est saturée. Les communes qui se situent autour des valeurs moyennes (compris entre 75 et 125 sur les deux contextes, 100 représentant la moyenne) sont représentées en blanc. 

Un graphique est associé à la représentation cartographique afin de visualiser le nuage de point sur lequel porte la représentation cartographique. Les communes de chaque même ZAU s'alignent alors selon un segment de droite dont la longueur exprime l'importance des disparités des communes qui ont fusionné et la pente la différence entre la moyenne de la ZAU et la moyenne nationale (@grasland2004) L'alignement des points selon différentes courbures de droites dans le repère permet ici d'apprécier l'effet de l'appartenance à une ZAU sur les inégalités induites par le potentiel financier. Basiquement, plus la pente du nuage de point de communes de même ZAU est importante, moins les régions qui la compose sont différenciées (les écarts intra-zone globaux étant faibles).



```{r bidev, eval = TRUE, out.width= '100%'}
# Supprimer 0 (transformations log impossible)
geomfus2011 <- geomfus2011[geomfus2011$gdevfr != 0,]
geomfus2011 <- geomfus2011[geomfus2011$mdevfr != 0,]

# Calculer map_bidev
xx <- map_bidev(x = geomfus2011, dev1 = "gdevfr", dev2 = "mdevfr",
                breaks = c(75, 150, 300))

# Générer les géométries et le vecteur de couleur
com <- xx$geom
cols <- xx$cols

par(mfrow = c(1,2), mar = c(0,4,0,0))

typoLayer(x = com, var = "bidev", border = NA, col = cols, lwd = 0.2, 
          legend.pos = "n")
plot(dep$geom, col = NA, lwd = 1, add = TRUE)

layoutLayer(title = paste0("Synthèse des deux déviations.\nVariable : ", num),
            author = "Source : INSEE, 2020.", scale = 50, col = "white", coltitle = "black")

plot_bidev(x = com,  dev1 = "gdevfr",  dev2 = "mdevfr", 
           dev1.lab = "Déviation nationale",
           dev2.lab = "Déviation aux ZAU de même appartenance",
           cex.lab = 0.8, breaks = c(75, 150, 300), cex.pt = 0.2, cex.axis = 0.5)
```




## | 4.3 Zoom

On prend ici 4 cas d'étude : communes de l'ancienne région Rhône-Alpes (qui présente des situations contrastées), avec un zoom sur sa partie Est (la plus touchée par les communes nouvelles), la région Normandie (dont le potentiel financier des communes est visiblement faible au regard contextes spatiaux identifiés en partie précédente), tout comme le département 49 (très dense en communes nouvelles). 

### || 4.3.1 Préparation des données et calcul des déviations

Les trois déviations suivantes sont calculées :
- Déviation générale : situation du potentiel financier par habitant au regard de la moyenne régionale (ou départementale pour le 49)
- Déviation intermédiaire : situation au regard des communes de même région (ou département) appartenant aux mêmes catégories de ZAU.
- Déviation locale : situation au regard des communes contigues. 

Ces trois déviations sont calculées simultanément grâce à la fonction `mst` du package `MTA`. La fonction renvoie une typologie codée de 0 à 7 qui renvoie la position de chaque commune sur les trois déviations, en fonction d'un seuil (*threshold*) prédéfini et d'une relation de supériorité ou d'infériorité (*superior*). 

On souhaite cibler les situations extrêmes (faibles ressources et importantes ressources). Nous calculons donc cette typologie pour les communes en situation favorable (`threshold = 125 , superior = TRUE`) et défavorable (`threshold = 75, superior = FALSE`). 


```{r case_studies}

# Extraction cas d'étude
norm <- subset (geom2011, REG == "23" | REG == "25") # Normandie
normCN <- subset (geomCN2020, REG == "28")

dep49 <- subset (geom2011, CODE_DEPT == "49" ) # Dep 49
dep49CN <- subset (geomCN2020, CODE_DEPT == "49")

ralp <- subset (geom2011, REG == "82") # Rhône-Alpes
ralpCN <- subset (geomCN2020, CODE_DEPT == "69" | CODE_DEPT == "73"
                  | CODE_DEPT == "74" | CODE_DEPT == "38"
                  | CODE_DEPT == "42" | CODE_DEPT == "01"
                  | CODE_DEPT == "26" | CODE_DEPT == "07")

ralppartiel <- subset (geom2011, CODE_DEPT == "69" | CODE_DEPT == "73"
                  | CODE_DEPT == "74" | CODE_DEPT == "38" | CODE_DEPT == "01") # Rhône-Alpes partiel
ralppartielCN <- subset (geomCN2020, CODE_DEPT == "69" | CODE_DEPT == "73"
                  | CODE_DEPT == "74" | CODE_DEPT == "38" | CODE_DEPT == "01")

```




On crée la fonction `colmst` pour gérer les couleurs et légendes des cartes de typologie qui suivent. Puis on représente les régions respectivement au-dessus et en-dessous des indices 125 et 75 (100 = moyenne) pour les trois contextes.  
``` {r function colmst, out.width= '100%'}
# Gestion des couleurs et des labels
colsmst <- function(x){
  
  coldf <- data.frame(colvec = c("#f0f0f0", "#fdc785","#ffffab","#fba9b0",
                                 "#addea6","#ffa100","#fff226","#e30020"),
                      mst = seq(0,7,1),
                      leg_val = c("∅","R -    -   ","   - Z -   ","R - Z -   ","   -    - C", "R -    - C", "   - Z - C", "R - Z - C"), # ligne pour disposer les lettres de manière plus lisible
                      # leg_val = c("0","R","Z","R-Z","C", "R-C", "Z-C", "R-Z-C"), # ligne d'origine
                      stringsAsFactors = FALSE)
  
  xx <- st_set_geometry(x, NULL)
  xx <- coldf[coldf$mst %in% xx[,"mst"],]
  cols <- xx$colvec
  leg_val <- as.vector(xx$leg_val)
  
  return(list("cols" = cols,  "leg_val" = leg_val))
}
``` 

### || 4.3.2 Normandie

``` {r MTA_Normandie, out.width= '100%'}
# Calculer les trois déviations
norm$gdev <- gdev(x = norm, var1 = num, var2 = denom)
norm$tdev <- tdev(x = norm, var1 = num, var2 = denom, key = "CATAEU2010")
norm$sdev <- sdev(x = norm, var1 = num, var2 = denom, order = 1)

# Situation supérieur à 125 (souvent favorable)
mst <- map_mst(x = norm, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 125, superior = TRUE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
fuz <- st_set_geometry(geomfus2011, NULL)
fuz$fuz <- 1
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]

# Aire d'étude pour faciliter la lisibilité
study_area <-subset (dep, CODE_DEPT == "27" | CODE_DEPT == "50"
                  | CODE_DEPT == "14" | CODE_DEPT == "61" | CODE_DEPT == "76" | CODE_DEPT == "35" )
plot(st_geometry(study_area), border = NA)

typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n", add = TRUE)

depnorm <- subset (dep, CODE_DEPT == "27" | CODE_DEPT == "50"
                  | CODE_DEPT == "14" | CODE_DEPT == "61" | CODE_DEPT == "76")
plot(st_geometry(depnorm), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nau-dessus de l'indice 125 :",
           nodata = FALSE, pos = c(3410000, 2930000), title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation favorable (Normandie)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "center",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2021", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "NORM ", num, " sit_fav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
norm <- merge (norm, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(norm)[length(norm)-1] <- "mst_sup" # Classification selon déviation supérieur à 125


# Situation inférieur à 75 (souvent défavorable)
mst <- map_mst(x = norm, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 75, superior = FALSE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]
plot(st_geometry(study_area), border = NA)

typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n", add = TRUE)

plot(st_geometry(depnorm), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nen-dessous de l'indice 75 :",
           nodata = FALSE, pos =  c(3410000, 2940000), title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation défavorable (Normandie)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "center",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2021", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "NORM ", num, " sit_defav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
norm <- merge (norm, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(norm)[length(norm)-1] <- "mst_inf" # Classification selon déviation inférieur à 75

```


### || 4.3.3 Maine-et-Loire


``` {r MTA_dep49, out.width= '100%'}
# Calculer les trois déviations
dep49$gdev <- gdev(x = dep49, var1 = num, var2 = denom)
dep49$tdev <- tdev(x = dep49, var1 = num, var2 = denom, key = "CATAEU2010")
dep49$sdev <- sdev(x = dep49, var1 = num, var2 = denom, order = 1)

# Situation supérieur à 125 (souvent favorable)
mst <- map_mst(x = dep49, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 125, superior = TRUE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
fuz <- st_set_geometry(geomfus2011, NULL)
fuz$fuz <- 1
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]
typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n")

depfig <- subset (dep, CODE_DEPT == "49")
plot(st_geometry(depfig), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nau-dessus de l'indice 125 :",
           nodata = FALSE, pos = "topleft", title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation favorable (Maine-et-Loire)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "right",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2020.", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "49 ", num, " sit_fav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
dep49 <- merge (dep49, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(dep49)[length(dep49)-1] <- "mst_sup" # Classification selon déviation supérieur à 125


# Situation inférieur à 75 (souvent défavorable)
mst <- map_mst(x = dep49, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 75, superior = FALSE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]
typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n")

plot(st_geometry(depfig), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nen-dessous de l'indice 75 :",
           nodata = FALSE, pos = "topleft", title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation défavorable (Maine-et-Loire)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "right",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2020.", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "49 ", num, " sit_defav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
dep49 <- merge (dep49, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(dep49)[length(dep49)-1] <- "mst_inf" # Classification selon déviation inférieur à 75

```



### || 4.3.4 Rhône-Alpes


``` {r MTA_ralp, out.width= '100%'}
# Calculer les trois déviations
ralp$gdev <- gdev(x = ralp, var1 = num, var2 = denom)
ralp$tdev <- tdev(x = ralp, var1 = num, var2 = denom, key = "CATAEU2010")
ralp$sdev <- sdev(x = ralp, var1 = num, var2 = denom, order = 1)

# Situation supérieur à 125 (souvent favorable)
mst <- map_mst(x = ralp, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 125, superior = TRUE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
fuz <- st_set_geometry(geomfus2011, NULL)
fuz$fuz <- 1
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]
typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n")

depfig <- subset (dep, CODE_DEPT == "69" | CODE_DEPT == "73"
                  | CODE_DEPT == "74" | CODE_DEPT == "38"
                  | CODE_DEPT == "42" | CODE_DEPT == "01"
                  | CODE_DEPT == "26" | CODE_DEPT == "07")
plot(st_geometry(depfig), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nau-dessus de l'indice 125 :",
           nodata = FALSE, pos = "topleft", title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation favorable (Rhône-Alpes)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "right",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2020.", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "RALP ", num, " sit_fav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
ralp <- merge (ralp, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(ralp)[length(ralp)-1] <- "mst_sup" # Classification selon déviation supérieur à 125


# Situation inférieur à 75 (souvent défavorable)
mst <- map_mst(x = ralp, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 75, superior = FALSE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]
typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n")

plot(st_geometry(depfig), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nen-dessous de l'indice 75 :",
           nodata = FALSE, pos = "topleft", title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation défavorable (Rhône-Alpes)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "right",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2020.", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "RALP ", num, " sit_defav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
ralp <- merge (ralp, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(ralp)[length(ralp)-1] <- "mst_inf" # Classification selon déviation inférieur à 75

```

### || 4.3.5 Rhône-Alpes partiel (cinq départements les plus à l'Est)


``` {r MTA_ralppartiel, out.width= '100%'}
# Calculer les trois déviations
ralppartiel$gdev <- gdev(x = ralppartiel, var1 = num, var2 = denom)
ralppartiel$tdev <- tdev(x = ralppartiel, var1 = num, var2 = denom, key = "CATAEU2010")
ralppartiel$sdev <- sdev(x = ralppartiel, var1 = num, var2 = denom, order = 1)

# Situation supérieur à 125 (souvent favorable)
mst <- map_mst(x = ralppartiel, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 125, superior = TRUE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
fuz <- st_set_geometry(geomfus2011, NULL)
fuz$fuz <- 1
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]
plot(st_geometry(ralp), col = NA, border = NA)
typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n", add = TRUE)

depfig <- subset (dep, CODE_DEPT == "69" | CODE_DEPT == "73"
                  | CODE_DEPT == "74" | CODE_DEPT == "38" | CODE_DEPT == "01")
plot(st_geometry(depfig), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nau-dessus de l'indice 125 :",
           nodata = FALSE, pos = "topleft", title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 4),]# Sélection, au hasard, de 4 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation favorable (Rhône-Ain-Isère-Savoies)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "right",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2020.", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "RALP-Partiel ", num, " sit_fav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
ralppartiel <- merge (ralppartiel, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(ralppartiel)[length(ralppartiel)-1] <- "mst_sup" # Classification selon déviation supérieur à 125


# Situation inférieur à 75 (souvent défavorable)
mst <- map_mst(x = ralppartiel, gdevrel = "gdev", tdevrel = "tdev", sdevrel = "sdev",
               threshold = 75, superior = FALSE)

# Unlist outputs of the function
com <- mst$geom

# Ne garder que les communes fusionnantes
com <- merge(com, fuz[,c("CODGEO", "fuz")], by.x = "CODGEO",
             by.y = "CODGEO", all.x = TRUE)
com <- com[!is.na(com$fuz),]
com <- com[order(com$mst),]

# Légende et couleurs
xx <- colsmst(x = com)
cols <- xx$cols
leg_val <- xx$leg_val

# Cartographie
par(mar = c(0,0,0,0), mfrow = c(1,1))
bb <- st_bbox(com)
bb <- st_as_sfc(st_bbox(bb + c(-60000,0,0,0), crs = 3035))
com <- com[!is.na(com$LIBGEO),]

plot(st_geometry(ralp), col = NA, border = NA)
typoLayer(x = com, var = "mst", border = "grey50",
          col = cols, lwd = 0.2, legend.pos = "n", add = TRUE)

plot(st_geometry(depfig), lwd = 1, col = NA, add = TRUE)

legendTypo(col = cols, categ = leg_val,
           title.txt = "Communes fusionnantes\nen-dessous de l'indice 75 :",
           nodata = FALSE, pos = "topleft", title.cex = .7, values.cex = .6)

toponymes <- com[com$mst == 7,] # Sélection des noms des communes correspondant à la classe 7
toponymes <- toponymes[sample(1:nrow(toponymes), 6),]# Sélection, au hasard, de 6 toponymes
labelLayer(toponymes, txt = "LIBGEO", halo = TRUE, overlap = FALSE, cex = 0.6)

layoutLayer(# title = paste0(nomnum, " : Communes nouvelles en situation défavorable (Rhône-Ain-Isère-Savoies)"),
            title = paste0("\n\n\n\n\n\n", nomnum), postitle = "right",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            source = "Source : INSEE, 2020.", author =  "G. Bideau, R. Ysebaert, 2021.
100: Moyenne des déviations
R: Situation au regard de la moyenne des communes de l'espace d'étude (région)
Z: Situation au regard de la moyenne des ZAU d'appartenance sur l'espace d'étude.
C: Situation au regard des communes contigues")
dev.print(device = svg, file = paste0("figures/Dev ", "RALP-Partiel ", num, " sit_defav", ".svg"))

# Intégration des données de déviation pour sauvegarde
st_geometry(com) <- NULL # On supprime les géométries car sinon fusion impossible
ralppartiel <- merge (ralppartiel, com[, c("CODGEO", "mst")], by = "CODGEO", all.x = TRUE)
colnames(ralppartiel)[length(ralppartiel)-1] <- "mst_inf" # Classification selon déviation inférieur à 75

```


### || 4.3.6 Sauvegarde des données obtenues
```{r Sauvegarde data deviation, eval = FALSE}

st_write(obj = norm [, c("CODGEO", "LIBGEO", "CODGEO_2020", "LIBGEO_2020", "mst_sup", "mst_inf")], dsn = paste0("Archives/sorties_2011-2020/norm_", num, ".gpkg"), layer = "norm", delete_layer = TRUE, quiet = TRUE)
st_write(obj = dep49 [, c("CODGEO", "LIBGEO", "CODGEO_2020", "LIBGEO_2020", "mst_sup", "mst_inf")], dsn = paste0("Archives/sorties_2011-2020/dep49_", num, ".gpkg"), layer = "dep49", delete_layer = TRUE, quiet = TRUE)
st_write(obj = ralp [, c("CODGEO", "LIBGEO", "CODGEO_2020", "LIBGEO_2020", "mst_sup", "mst_inf")], dsn = paste0("Archives/sorties_2011-2020/ralp_", num, ".gpkg"), layer = "ralp", delete_layer = TRUE, quiet = TRUE)



# Pour importer les données concernant le taux de chômage
norm_P09_CHOM1564 <- st_read("Archives/sorties_2011-2020/norm_P09_CHOM1564.gpkg", layer = "norm", quiet = TRUE) 
dep49_P09_CHOM1564 <- st_read("Archives/sorties_2011-2020/dep49_P09_CHOM1564.gpkg", layer = "dep49", quiet = TRUE) 
ralp_P09_CHOM1564 <- st_read("Archives/sorties_2011-2020/ralp_P09_CHOM1564.gpkg", layer = "ralp", quiet = TRUE) 

# Pour importer les données concernant le potentiel financier
norm_P11_POT_FIN <- st_read("Archives/sorties_2011-2020/norm_P11_POT_FIN.gpkg", layer = "norm", quiet = TRUE) 
dep49_P11_POT_FIN <- st_read("Archives/sorties_2011-2020/dep49_P11_POT_FIN.gpkg", layer = "dep49", quiet = TRUE) 
ralp_P11_POT_FIN <- st_read("Archives/sorties_2011-2020/ralp_P11_POT_FIN.gpkg", layer = "ralp", quiet = TRUE) 
```

### || 4.3.7 Croisement de différentes données

Certaines communes ont des situations très contrastées, c'est-à-dire une situation favorable vis-à-vis de certains contextes et défavorables vis-à-vis d'autres.
```{r Croisement data deviations, eval = FALSE}
dep49_P11_POT_FIN <- as.data.frame(dep49_P11_POT_FIN) # Pour que le sf devienne un simple data frame (sinon, on peut aussi utiliser st_geometry(data) <- NULL qui retire/supprime la géométrie
dep49Croisement <- merge (dep49_P09_CHOM1564, dep49_P11_POT_FIN[, c("CODGEO", "mst_sup", "mst_inf")], by = "CODGEO")

colnames(dep49Croisement) <- c("CODGEO", "LIBGEO", "CODGEO_2020", "LIBGEO_2020", "mst_sup_CHOM", "mst_inf_Chom", "mst_sup_PotFin", "mst_inf_PotFin","geometry")

summary(dep49Croisement$mst_inf_Chom >0)


```




```{r Nettoyage espace de travail fin section 4, echo = FALSE}
rm(list=ls())
```

# 5 - ACP - CAH


## | 5.0 Préparation des données

```{r Prep data section 4, eval = TRUE}
geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE) # Les  communes qui ont participé à la création de communes nouvelles (appelées communes fusionnantes).
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE) # Départements

# Import des données
load("Archives/data_2011-2020/refdata.Rdata")
rm(df2020)

df2011 <- df2011[, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "CATAEU2010", "FusPhas", "COM_NOUV", "FUSION",  "P09_CHOM1564_RT", "P09_ETUD1564_RT", "P09_RETR1564_RT", "C09_ACT1564_Agr_RT", "C09_ACT1564_ArtCom_RT", "C09_ACT1564_Cadr_RT", "C09_ACT1564_ProfInt_RT", "C09_ACT1564_Empl_RT", "C09_ACT1564_Ouvr_RT", "P09_POP0014Y_RT", "P09_POP1529Y_RT", "P09_POP3044Y_RT", "P09_POP4559Y_RT", "P09_POP6074Y_RT", "C09_ACTOCC_OUT_RT", "P11_POT_FIN", "P09_POP", "REG", "CODE_DEPT", "P11_POT_FIN_RT")]
datafus2011 <- subset(df2011, COM_NOUV == "OUI") # Désigne les données concernant les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes

# Appariement des données
geomfus2011 <- merge(geomfus2011, datafus2011, by = "CODGEO")

# Import données pour les noms de variables
ratio <- as.data.frame(read_excel("data-raw/meta.xlsx", sheet = "ratios"))
row.names(ratio) <- ratio$Numerator_Code

```


## | 5.1 Sélectionner les variables d'intérêt

```{r Select les variables pour la CAH}

selecVar <- c("CODGEO","CODE_DEPT", "CATAEU2010", "LIBGEO_2020", "P09_CHOM1564_RT", "P09_ETUD1564_RT", "P09_RETR1564_RT", "C09_ACT1564_Agr_RT", "C09_ACT1564_ArtCom_RT", "C09_ACT1564_Cadr_RT", "C09_ACT1564_ProfInt_RT", "C09_ACT1564_Empl_RT", "C09_ACT1564_Ouvr_RT", "P09_POP0014Y_RT", "P09_POP1529Y_RT", "P09_POP3044Y_RT", "P09_POP4559Y_RT", "P09_POP6074Y_RT", "C09_ACTOCC_OUT_RT")
datafus2011 <- datafus2011[,selecVar]

PourCAH <- na.omit(datafus2011)
row.names(PourCAH) <- PourCAH$CODGEO
PourCAH$CODGEO <- NULL
PourCAH$CODE_DEPT <- NULL
PourCAH$CATAEU2010 <- NULL
PourCAH$LIBGEO_2020  <- NULL
NbrVariables <- ncol(PourCAH)

selecVarCAH <- colnames(PourCAH)


```

## | 5.2 Réalisation de la typologie et valeurs

```{r typologie, out.width= '100%'}
res.pca <- PCA(PourCAH, ncp = 5, graph = FALSE)

res.hcpc <- agnes(res.pca$ind$coord, metric = "euclidiean", method = "ward")


# Réalisation du dendrogramme en passant par plot
dendro.hcpc <- as.dendrogram(res.hcpc)
plot(dendro.hcpc, leaflab = "none", ylab = "Dissimilarité")


# Affichage de différents graphiques pour aider au découpage
sortedHeight <- sort(res.hcpc$height^2, decreasing = TRUE)
plot(sortedHeight,
     type = "h",
     xlab = "Noeuds",
     ylab = "Niveau d'agrégation")

relHeight <- sortedHeight / sum(sortedHeight) * 100
cumHeight <- cumsum(relHeight)
barplot(relHeight[1:30], names.arg = seq(1, 30, 1),
        col = "black", border = "white", xlab = "Noeuds",
        ylab = "Part de l'inertie totale (%)",
        main = "Diagramme de niveaux")


# Coupure de l'arbre (k = nombre de classes)
nclass <- 5
cluspop <- cutree(res.hcpc, k = nclass)

# cluspop
```

## || 5.2.1 Valeurs absolues

```{r Graphes variables valeur brute, out.width= '100%'}
# Noms pour typo avec les navetteurs, avec 5 classes
NomsGroupesCAH <- c("Groupe 1 PPCQ", # Proche Périphérie, Cadres, Quinquagénaires
                    "Groupe 2 PFO", # Périphéries Familiales et Ouvrières
                    "Groupe 3 MOARO", # Moyen, Ouvriers, Agriculteurs, Retraités, Out.
                    "Groupe 4 VAR", # Vieillissantes, Agricoles et Rurales
                    "Groupe 5 REAV" # Rurales, Enclavées, Agricoles et Vieillissantes
)
# Si on veut le nom complet :
# NomsGroupesCAH <- c("Groupe 1 : Proche Périphérie, Cadres, Quinquagénaires (PPCQ)",
#                     "Groupe 2 : Périphéries Familiales et Ouvrières (PFO)",
#                     "Groupe 3 : Moyen, Ouvriers, Agriculteurs, Retraités, Out (MOARO)",
#                     "Groupe 4 : Vieillissantes, Agricoles et Rurales (VAR)",
#                     "Groupe 5 : Rurales, Enclavées, Agricoles et Vieillissantes (REAV)")

# Si on ne veut pas définir de noms
# NomsGroupesCAH <- paste ("Groupe",1 :nclass)

# On intègre ces données dans le tableau de départ
PourCAH <- as.data.frame(PourCAH, stringsAsFactors = FALSE)
PourCAH$Groupes <- factor(cluspop,
                          levels = 1:nclass,
                          labels = paste(NomsGroupesCAH))

PourCAH$CODGEO <- row.names(PourCAH)
# Calcul de la moyenne des variables
clusProfile <- aggregate(PourCAH [, 1:NbrVariables],
                         by = list(PourCAH$Groupes),
                         mean)
colnames(clusProfile)[1] <- "Groupes"
clusLong <- melt(clusProfile, id.vars = "Groupes")

ggplot(clusLong) +
  geom_bar(aes(x = variable, y = value, fill = Groupes),
           stat = "identity") +
   scale_fill_manual(values=c("#e41a1c","#377eb8","#4daf4a","#984ea3","#ff7f00","#ffff33","#a65628")) + # Pour 7
  facet_wrap(~ Groupes) +
  coord_flip() +
  theme_bw()

```
## || 5.2.2 Valeurs moyennes
```{r Valeurs moyennes CAH, out.width= '100%'}

# Calculs des valeurs moyennes (pour comparaison)
# On identifie les variables en stock
VarCAHBrutes <- stringr::str_replace(selecVarCAH, "Y_RT", "")
VarCAHBrutes <- stringr::str_replace(VarCAHBrutes, "_RT", "")
# Import données totales
load("Archives/data_2011-2020/refdata.Rdata")
rm(df2020)
# Sélection données utiles
pourmoyennesCAH <- na.omit(subset(df2011, COM_NOUV == "OUI"))
moyennesCAH <- data.frame()
for (i in VarCAHBrutes){
  a <- ratio[i, "Denominator_Code"]
  b <- ratio[i, "Coeff"]
  c <- sum(df2011[, i], na.rm = TRUE)
  d <- sum(df2011[, a], na.rm = TRUE)
  moyfr <- round(b * c/d, 2)
  e <- sum(pourmoyennesCAH[, i], na.rm = TRUE)
  f <- sum(pourmoyennesCAH[, a], na.rm = TRUE)
  moyCFus <- round(b * e/f, 2)
  g <- ratio[i, "CODE"]
  h <- c(g, moyfr, moyCFus)
  moyennesCAH <- rbind(moyennesCAH, h, stringsAsFactors= FALSE)
  rm( a, b, c, d, e, f, g, h, moyfr, moyCFus)
}

colnames(moyennesCAH) <- c("Variable", "France", "CommunesFusionnantes")
moyennesCAH$Variable <- as.factor(moyennesCAH$Variable)
moyennesCAH$France <- as.numeric(moyennesCAH$France)
moyennesCAH$CommunesFusionnantes <- as.numeric(moyennesCAH$CommunesFusionnantes)
moyennesCAH$DiffComFusComFr <- moyennesCAH$CommunesFusionnantes - moyennesCAH$France

aa<- ggplot(data = moyennesCAH) +
  geom_bar(aes(x = Variable, y = France), stat = "identity") + coord_flip()
bb <- ggplot(data = moyennesCAH) +
  geom_bar(aes(x = Variable, y = CommunesFusionnantes), stat = "identity") + coord_flip()
cc <- ggplot(data = moyennesCAH) +
  geom_bar(aes(x = Variable, y = DiffComFusComFr), stat = "identity") + coord_flip()
cowplot::plot_grid(aa, bb, cc, ncol = 1, nrow = 3)
rm(aa,bb,cc)



```

## || 5.2.3 Valeurs standardisées

```{r Graphes variables valeurs stand, out.width= '100%'}

# On intègre ces données dans le tableau de départ

PourCAHz <- scale(PourCAH[,c(1:NbrVariables)])
PourCAHz <- as.data.frame(PourCAHz, stringsAsFactors = FALSE)

PourCAHz$Groupes <- PourCAH$Groupes
PourCAH$Groupes <- factor(cluspop,
                          levels = 1:nclass,
                         labels = paste(NomsGroupesCAH)) 

PourCAHz$CODGEO <- row.names(PourCAHz)
# Calcul de la moyenne des variables
clusProfileStd <- aggregate(PourCAHz [, 1:NbrVariables],
                         by = list(PourCAH$Groupes),
                         mean)
colnames(clusProfileStd)[1] <- "Groupes"
clusLongStd <- melt(clusProfileStd, id.vars = "Groupes")
clusLongStd <- merge(clusLongStd, ratio[, 1:2], by.x = "variable", by.y = "CODE") # Pour lisibilité du graphique
colnames(clusLongStd)[4] <- "Variable"

ggplot(clusLongStd) +
  geom_bar(aes(x = Variable, y = value, fill = Groupes),
           stat = "identity") +
  scale_fill_manual(values=c("#e41a1c","#377eb8","#4daf4a","#984ea3","#ff7f00","#ffff33","#a65628","#f781bf")) +   facet_wrap(~ Groupes) +
  coord_flip() + theme_bw()
```

## || 5.2.4 Cartographie

```{r Carto Typo}

# Remettre groupes dans geomfus2011 pour cartographie
typo <- merge(geomfus2011,PourCAH[ , c("CODGEO","Groupes")], by = "CODGEO")


# mf_export(x = typo, export = "svg", filename = "figures/TypoEspaceGeo.svg", 
#           width = 5, theme = "nevermind") # Si souhait d'export
## Carte Typo nationale des communes fusionnées
par(mfrow = c(1, 1))
par(mar=c(0,0,1.2,0))
plot(st_geometry(dep), border = "#1A1A19",lwd = 1)

typoLayer(x = typo, var = "Groupes",  
          col = c("#e41a1c","#377eb8","#4daf4a","#984ea3","#ff7f00","#ffff33","#a65628","#f781bf"),
          
          border = NA, 
          legend.title.cex = 0.7,
          legend.values.cex = 0.6,
          legend.pos = "n", add = T)

layoutLayer(title = "Typologie exploratoire des communes fusionnantes (2012-2020)",
            author = "G. Bideau, R. Ysebaert, 2021.",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            sources = "Sources : INSEE, IGN, 2020.")
# dev.off() # Si souhait d'export
```

## | 5.3 Comparaison et analyse des groupes

Dans le but de comparer un profil avec la moyenne française, on extrait les données de chaque groupe défini par la CAH (données issues de `clusLong` et `clusProfile`) et on les compile dans un tableau contenant déjà les données des moyennes françaises et des communes fusionnantes (`moyennesCAH`).
En sortie, un tableau est créé pour chaque groupe.


#### || 5.3.1 Comparaison tous groupes

```{r Tableaux comparaisons tous groupes, results='asis', eval = TRUE}

# Tableau pour comparaison entre les groupes
clusProfile2 <- as.data.frame(t(clusProfile))
colnames(clusProfile2) <- clusProfile2[1,]
clusProfile2 <- clusProfile2[ c(2:nrow(clusProfile2)),]
compare <- cbind(moyennesCAH, clusProfile2)

for (i in NomsGroupesCAH){
  a <- which(colnames(compare)== i)
  b <- as.numeric(compare[,a])
  compare[,a] <- as.numeric(compare[,a])
  compare[paste0(i,"_DiffAvecFrance")] <- b - compare$France
  compare[paste0(i,"_DiffAvecComFus")] <- b - compare$CommunesFusionnantes
  rm(a, b)
}

kable(compare, row.names = F, digits = 2, caption = "Tableau de comparaison entre les groupes")


comparaisons <- data.frame()
for (i in NomsGroupesCAH){
  a <- subset(typo, typo$Groupes == i)
  Nb <- nrow(a)
  b <- round(mean(a$P11_POT_FIN), 2)
  bb <- round(mean(a$P11_POT_FIN_RT), 2)
  c <- table(a$CATAEU2010)
  h <- c(i, Nb, b, bb, c)
  comparaisons <- rbind(comparaisons, h, stringsAsFactors= FALSE)
  rm( a, b, bb, c, h, Nb)
} 
colnames(comparaisons) <- c("Groupes", "Nombre", "Moy_P11_POT_FIN", "Moy_P11_POT_FIN_RT", "111","112","120","211","212","221","222","300","400")
mean(typo$P11_POT_FIN)
mean(typo$P11_POT_FIN_RT)

tmp <- comparaisons[, c("Groupes", "Nombre", "111","112","120","211","212","221","222","300","400")]
kable(tmp, row.names = F, digits = 1, caption = "Code de Zonage en aire urbaine dans chaque groupe",
      col.names = c("Groupes", "Nombre de communes", "Unité urbaine", "Couronne périurbaine", "Communes multipolarisées", "Unité urbaine", "Couronne périurbaine", "Unité urbaine", "Couronne périurbaine", "Autres communes multipolarisées", "Communes hors influence des pôles"), format = "html") %>%
  kableExtra::add_header_above(c(" " = 2, "Grandes aires urbaines" = 3, "Pôles moyens" = 2, "Petits pôles" = 2," " = 2)) 

```

#### || 5.3.2 Tableaux simplifiés


```{r Tableaux simplifies comparaison, results='asis', eval = TRUE}

x <- length(NomsGroupesCAH)

table <- compare[, 1:(4+x)]
table[, 5:(4+x)] <- round (table[, 5:(4+x)], 2)

min <- min(table[, c(2, 3, 5:ncol(table))])
max <- max(table[, c(2, 3, 5:ncol(table))])

# Pour donner la description complète et propre de la variable
table <- merge(table, ratio[, 1:2], by.x = "Variable", by.y = "CODE")

# condformat(table) %>%
condformat(table[, c(length(table), 2:(length(table)-1))]) %>% # Pour avoir la description complète des variables
          # rule_fill_bar("Valeur pour la France entière (A)", limits = c(0, 100), low = "darkgreen", high = "darkgreen") %>%
          
          rule_fill_gradient2("France", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("CommunesFusionnantes", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 1 PPCQ", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 2 PFO", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 3 MOARO", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 4 VAR", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 5 REAV", low = "darkblue", high = "red", limits = c(min, max)) %>%
          
  theme_caption(caption = "Tableau de comparaison entre les groupes") %>%
  theme_htmlWidget(number_of_entries = nrow(compare))

table2 <- table[, c(length(table), 2:4)]
min <- min(table2[4])
max <- max(table2[4])
colnames(table2) <- c ("Variable", 
                            "Valeur pour la France entière (A)",
                            "Valeur pour les communes fusionnantes (B)",
                            "Différence ComFus/France (B-A)")
print(condformat(table2) %>%
  rule_fill_gradient2("Différence ComFus/France (B-A)", low = "blue", high = "red", limits = c(min, max)) %>%
  theme_caption(caption = "Situation des communes fusionnantes vis-à-vis des communes françaises") %>%
  theme_htmlWidget(number_of_entries = nrow(compare)))



test <- melt(compare[, c(1, 2, 5:(4+x)) ], id.vars = "Variable")
colnames(test) <- c("Variable", "Groupes", "Valeur")
ggplot(test) +
  geom_bar(aes(x = Variable, y = Valeur, fill = Groupes),
           stat = "identity") +
  #  scale_fill_grey() +
  scale_fill_manual(values=c("#a65628", "#e41a1c","#377eb8","#4daf4a","#984ea3","#ff7f00")) + 
  #  scale_fill_manual(values=c("#e41a1c","#377eb8","#4daf4a","#984ea3","#ff7f00","#ffff33","#a65628")) + # Pour 7
  facet_wrap(~ Groupes) +
  coord_flip() + theme_bw()


test <- melt(compare[, c(1, 4, 11, 13, 15, 17, 19) ], id.vars = "Variable")
colnames(test) <- c("Variable", "Différence avec la moyenne des communes fusionnantes", "Valeur")
levels(test$`Différence avec la moyenne des communes fusionnantes`) <- c("France",
                         "Groupe 1", "Groupe 2", "Groupe 3", "Groupe 4", "Groupe 5")
ggplot(test) +
  geom_bar(aes(x = Variable, y = Valeur, fill = `Différence avec la moyenne des communes fusionnantes`),
           stat = "identity") +
  #  scale_fill_grey() +
  scale_fill_manual(values=c("#a65628", "#e41a1c","#377eb8","#4daf4a","#984ea3","#ff7f00")) + 
  facet_wrap(~ `Différence avec la moyenne des communes fusionnantes`) +
  coord_flip() + theme_bw() +
  labs(title = "Différence avec la moyenne des communes fusionnantes")+ theme(legend.position='none')


```


#### || 5.3.3 Tableaux comparaison groupe par groupe



```{r Tableaux comparaison groupe par groupe, results='asis', eval = TRUE}

x <- length(NomsGroupesCAH)
min <- min(compare[, (5+x):ncol(compare)])
max <- max(compare[, (5+x):ncol(compare)])
rm(x)

# Boucle donnant les valeurs pour chaque groupe, avec éléments de comparaison d'un profil avec la moyenne française
for (i in NomsGroupesCAH){
  clusLongGr <- subset(clusLong, clusLong$Groupes == i)
  compare <- merge(moyennesCAH, clusLongGr[, c("variable", "value")], by.x = "Variable", by.y = "variable")
  compare$DiffAvecFr <- compare$value - compare$France
  compare$DiffAvecComFus <- compare$value - compare$CommunesFusionnantes
  compare[, 2:length(compare)] <- round(compare[, 2:length(compare)], 1)

  n <- stringr::str_sub(i, 8, 8)
  assign(paste0("compare_Gr", n), compare)
  # print(kable(compare, row.names = F, caption = i))
  colnames(compare) <- c ("Variable", 
                            "Valeur pour la France entière (A)",
                            "Valeur pour les communes fusionnantes (B)",
                            "Différence ComFus/France (B-A)",
                            "Valeur pour le groupe étudié (C)",
                            "Différence Groupe/France (C-A)",
                            "Différence Groupe/ComFus (C-B)")

  table <- condformat(compare) %>%
          rule_fill_bar("Valeur pour la France entière (A)", limits = c(0, 100), low = "darkgreen", high = "darkgreen") %>%
          rule_fill_bar("Valeur pour les communes fusionnantes (B)", limits = c(0, 100), low = "darkgreen", high = "darkgreen") %>%
          rule_fill_bar("Valeur pour le groupe étudié (C)", limits = c(0, 100), low = "darkgreen", high = "darkgreen") %>%
          rule_fill_gradient2("Différence ComFus/France (B-A)", low = "darkblue", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Différence Groupe/France (C-A)", low = "darkblue", high = "red",  limits = c(min, max)) %>%
          rule_fill_gradient2("Différence Groupe/ComFus (C-B)", low = "darkblue", high = "red",  limits = c(min, max))%>%
          theme_caption(caption = i) %>%
          theme_htmlWidget(number_of_entries = nrow(compare))
  print(knit_print(table))
  rm(compare, n, table)
} 

```

#### || 5.3.4 Comparaisons des moyennes

Il est important de préciser que, comme toujours, les détails des calculs statistiques ont toute leur importance. Jusqu'ici, les moyennes ont été calculées sur l'ensemble de la population des ensemble étudiés. Par exemple, le chiffre de 66,38 % d'actifs occupés hors de leur commune de résidence, désigne le nombre de personnes quittant leur commune pour aller travailler. Or, les chiffres sont différents si on fait, désormais, apparaître les moyennes des taux communaux d'actifs occupés hors de leur commune de résidence
```{r Tableaux comparaison moyennes et medianes, results='asis', eval = TRUE}

# NB : On reprend les données déjà élaborées dans le 5.2.2
# Import données totales
moyennesComCAH <- data.frame()
for (i in selecVarCAH){
  a <- round(mean(df2011[, i], na.rm = TRUE), 2)
  b <- round(median(df2011[, i], na.rm = TRUE), 2)
  c <- round(mean(datafus2011[, i], na.rm = TRUE), 2)
  d <- round(median(datafus2011[, i], na.rm = TRUE), 2)
  
  h <- c(i, a, b, c, d)
  moyennesComCAH <- rbind(moyennesComCAH, h, stringsAsFactors= FALSE)
  rm( a, b, c, d, h)
}

colnames(moyennesComCAH) <- c("Variable", "Comfr_moy", "Comfr_med", "Comfus_moy", "Comfus_med")
moyennesComCAH <- merge(moyennesComCAH, ratio[, 1:2], by.x = "Variable", by.y = "CODE")
row.names(moyennesComCAH) <- moyennesComCAH$DESCRIPTION
moyennesComCAH[1] <- moyennesComCAH$DESCRIPTION
kable(moyennesComCAH[, 1:5], row.names = FALSE, col.names = c("", "Moyenne", "Médiane", "Moyenne", "Médiane"), digits = 2, format = "html")  %>%
  kableExtra::add_header_above(c("Variable" = 1, "Communes françaises" = 2, "Communes fusionnantes" = 2))
```


Ainsi, il est nécessaire d'être prudent sur l'interprétation des taux de navetteurs, car si la moyenne française est bien d'environ 66 %, la moyenne des communes françaises est supérieur à 74 % et la médiane des communes françaises à 78 %. C'est-à-dire que plus de la moitié des communes françaises ont un taux de navetteur supérieur à 78 % alors que cette médiane n'est que de 76 % chez les communes fusionnantes. Cela étant du, principalement, à la sous-représentation des navetteurs dans les communes très peuplées (au premier rang desquelles Paris, Lyon, Marseille etc). Par conséquent, la question des navetteurs est davantage quelque chose qui distingue les communes fusionnantes entre elles qu'une caractéristique commune. Pour les autres variables étudiées, il y a moins de différences entre les moyennes globales ou les moyennes par communes.

#### || 5.3.5 Analyse de la typologie


Le profil moyen des communes fusionnantes met en avant certaines caractéristiques. Les plus frappantes différence supérieur à 2% vis-à-vis de la moyenne française) sont une sur-représentation, dans l'ordre, des ouvriers, des actifs employés hors de la commune, des agriculteurs et des retraités. Inversement, on observe une sous-représentation des cadres, des étudiants, des 15-29 ans, des chômeurs et des professions intellectuelles.

En particulier, tous les groupes ont, systématiquement, par rapport à la moyenne française, deux caractéristiques communes : d'un côté, plus d'agriculteurs, d'artisans-commerçants ; de l'autre côté, moins de chômeurs, d'étudiants, de cadres, d'employés et de 15-29 ans.

Cette vision générale révèle néanmoins des divergences à l'intérieur du groupe des communes nouvelles. Une classification ascendante hiérarchique nous a permis d'identifier cinq groupes.

Le groupe 1 (rouge, 540 communes) contient des communes appartenant fréquemment à la périphérie des grands pôles urbains (277 communes), avec une sur-représentation, même vis-à-vis de l'ensemble des communes fusionnantes, des actifs travaillant hors de leur commune de résidence. En revanche, ce groupe s'inscrit par plusieurs caractéristiques en contrepoint du profil moyen des communes fusionnantes en ayant davantage de cadres, de professions intellectuelles et de 45-59 ans. On peut dénommer ce groupe le profil "PPCQ" (Proche Périphérie, Cadres, Quinquagénaires). On y retrouve, par exemple, des communes comme Annecy-le-Vieux, Pringy et Seynod (commune nouvelle d'Annecy), les trois communes ayant conduit à la commune nouvelle de Kaysersberg Vignoble1, certaines des communes constituant les communes nouvelles de Cherbourg-en-Cotentin, ou encore la totalité de la commune de Valloire-sur-Cisse (près de Blois).

Le groupe 2 (bleu, 689 communes) est caractérisé par des communes fusionnantes qui sont encore avec un fort taux de navetteurs et fréquemment (320 communes) dans la couronne des pôles urbains mais avec la présence plus importante de communes multipolarisées, soit par de grandes aires urbaines soit par d'autres (respectivement 113 et 163 communes). Il s'agit de communes plus familiales que la moyenne (00-14 ans et 30-44 ans), avec également davantage d'ouvriers. On peut dénommer ce groupe le profil "PFO" (Périphéries Familiales et Ouvrières). Des exemples parmi les plus frappants se retrouvent dans le Maine-et-Loire, formant une couronne autour d'Angers. On peut citer la commune nouvelle de Chemillé-en-Anjou (commune chef-lieu exclue, c'est à noter). On en retrouve également en Normandie (sept des vingt communes de Souleuvre-en-Bocages, huit des dix-neuf communes de La Hague) ou vers les Alpes (comme La Plagne Tarentaise, en Savoie).

Le groupe 3 (vert, 874 communes) révèle des caractéristiques proche du profil moyen des communes fusionnantes. Il est caractérisé, en particulier, par la sur-représentation des ouvriers, des agriculteurs, mais aussi des retraités et des actifs travaillant hors de la commune. On peut d'ailleurs remarquer que les catégories d'aires urbaines les plus représentées sont autres communes multipôlarisées et les communes hors influence des pôles. On peut dénommer ce groupe le profil "MOARO" (Moyen, Ouvriers, Agriculteurs, Retraités, Out). Il est particulièrement présent dans l'Ouest (Pays-de-la-Loire, Bretagne, Normandie) avec neuf des vingt-deux communes de Livarot-Pays-d'Auge (Calvados), la totalité de Saint-Sauveur-Villages (sept communes de la Manche) et neuf des dix communes de Tourouvre au Perche (Orne). À noter que c'est, avec le groupe 1, celui où on peut retrouver des communes centres (23), qui sont dans le groupe 3 par l'importance de leur population ouvrière, comme à La Hague ou Cherbourg.

Le groupe 4 (mauve, 213 communes) contient des communes marquées par une forte présence des retraités, des personnes âgés et des agriculteurs. Il s'agit, très majoritairement (136 communes) de communes hors influences des pôles. On peut, éventuellement, remarquer une présence des ouvriers plus importante que par rapport à la moyenne française (+4,8%) mais qui reste inférieure à la moyenne des communes fusionnantes. On peut bien parler ici de communes "VAR" (Vieillissantes, Agricoles et Rurales). Ces communes se retrouvent sans polarité particulière en France, que ce soit dans l'Ouest avec quatre des six communes de Belforêt-en-Perche (Orne) ou davantage au sud avec  trois des quatre communes de Porte-du-Quercy (Lot) et des petits binômes comme Castelnau d'Auzan Labarrère (Gers) ou Castels et Bézenac (Dordogne).

Le groupe 5 (orange, 194 communes), enfin, ressemble au groupe 4 par la présence de populations plus âgées et agricoles mais cette dernière caractéristique est bien plus affirmée, ainsi que le pourcentage de communes hors influences des pôles (127 communes). Surtout, ce dernier élément peut être mis en lien avec le fait que le groupe 5 a beaucoup moins d'actifs travaillant hors de la commune de résidence que la moyenne française ou des communes fusionnantes. On peut donc parler de communes "REAV" (Rurales, Enclavées, Agricoles et Vieillissantes). Ces communes sont décentrées par rapport à l'ensemble des communes nouvelles françaises : elles se trouvent davantage dans la partie sud et sud-est de la France, mais à distance des littoraux, comme par exemple Mont Lozère et Goulet (Lozère) ou la majorité de Neuvéglise-sur-Truyère (Cantal) et Argences en Aubrac (Aveyron).



## | 5.4 Chaque CN est-elle composée d'un seul type en fonction de la typologie réalisée ?

À partir de la typologie réalisée, permettant de catégoriser les communes fusionnantes sur la base de données socio-économiques, nous pouvons étudier la composition des communes nouvelles sur ce plan.

```{r Composition des CN en fonction de la typologie}

# Définition d'un tableau comportant le nombre de communes fusionnantes par commune nouvelle
count_CN_typo <- plyr::count(typo, "CODGEO_2020")

mesCommunes <- count_CN_typo$CODGEO_2020

df <- typo
results <- data.frame(matrix(ncol=nclass, nrow=0))

for (i in mesCommunes) { # Pour chaque identifiant de commune nouvelle, 
  toto <- subset (df, CODGEO_2020 == i ) # Ne garder que les communes fusionnantes y ayant participé
  a <- table(toto$Groupes) # Relever les groupes des communes fusionnantes
  results <- rbind(results,a) # Combiner les résultats, par lignes
  rm(a, toto) # Supprimer "a"
}
# On renomme les colonnes
colnames(results) <- NomsGroupesCAH
count_CN_typo <- cbind(count_CN_typo, results)

# On identifie la variable la plus fréquente
count_CN_typo$max2 <- apply(count_CN_typo[, 3:(nclass+2)], 1, function(x) max(x, na.rm = TRUE))
# Quel est le groupe de typo revenant le plus fréquemment dans une CN
count_CN_typo$Typomaj <- colnames(count_CN_typo[, 3:(nclass+2)])[apply(count_CN_typo[, 3:(nclass+2)], 1, which.max)]

# On note si une CN a des communes fusionnantes avec un groupe de typo identique
count_CN_typo$TypoIdent <- ifelse(count_CN_typo$max == count_CN_typo$freq, TRUE, FALSE)
summary(count_CN_typo$TypoIdent)
# On note si une CN a des communes fusionnantes avec un groupe de typo presque identique (max 25% de communes ayant un type différent)
count_CN_typo$TypopresqIdent <- ifelse((count_CN_typo$freq - count_CN_typo$max2)/count_CN_typo$freq <= 0.25, TRUE, FALSE)
summary(count_CN_typo$TypopresqIdent)

# On extrait les CN ayant des communes fusionnante avec un groupe de typo identique
CNTypoIdent <- subset(count_CN_typo, TypoIdent==TRUE)
CNTypoIdent <- merge(CNTypoIdent, typo[, c("CODGEO", "Groupes")], by.x = "CODGEO_2020", by.y = "CODGEO", all.x = TRUE)

  
# Quel pourcentage de chaque groupe dans les communes nouvelles homogènes ?
tabcont<-summary(CNTypoIdent$Groupes)
# Quel pourcentage de chaque groupe est majoritaire ?
count_CN_typo$Typomaj <- as.factor(count_CN_typo$Typomaj)
tabcont2<-summary(count_CN_typo$Typomaj)
# Pour comparaison : pourcentages de chaque groupe dans les communes fusionnantes
tabcont3<-summary(typo$Groupes)
round(100*prop.table(tabcont,margin=),1) # Pourcentages de chaque groupe en fonction de la totalité des communes nouvelles homogènes
round(100*prop.table(tabcont2,margin=),1) # Pourcentages de chaque groupe majoritaire en fonction de la totalité des communes fusionnantes
round(100*prop.table(tabcont3,margin=),1) # Pourcentages de chaque groupe en fonction de la totalité des communes fusionnantes

tableau <- rbind(
  summary(CNTypoIdent$Groupes),
  round(100*prop.table(tabcont,margin=),1) * 100 / nrow(typo),
  round(100*prop.table(tabcont,margin=),1),
  summary(count_CN_typo$Typomaj),
  round(100*prop.table(tabcont2,margin=),1),
  summary(typo$Groupes),
  round(100*prop.table(tabcont3,margin=),1)
)
row.names(tableau) <- c(
  "Nombre de communes nouvelles regroupant des communes homogènes du point de vue de la typologie",
  "Pourcentages en fonction de la totalité des communes nouvelles",
  "Pourcentages en fonction de la totalité des communes nouvelles homogènes",
  "Nombre de communes nouvelles ayant un type majoritaire",
  "Pourcentages de chaque groupe majoritaire en fonction de la totalité des communes fusionnantes",
  "Nombre de communes fusionnantes par groupe",
  "Pourcentages de chaque groupe en fonction de la totalité des communes fusionnantes")

kable(tableau, align = "c", digits = 1)

```

Conclusion : Une large majorité des communes nouvelles sont, du point de vue de notre typologie, composées de communes au profil hétérogène.
Lorsque les communes nouvelles sont homogène du point de vue du profil des communes fusionnantes, il s'agit, plus fréquemment, des groupes 1, 2 et 3. Mais si on compare ces pourcentages à la place de ces groupes dans la population totale, on observe surtout qu'un groupe est bien plus présent dans les communes homogènes que dans la population totale : le groupe 1. Inversement, le groupe 5 est bien moins présent dans les communes nouvelles homogènes que dans l'ensemble des communes fusionnantes.
On pourrait donc mettre en avant la création de communes nouvelles plus fréquemment homogènes en contexte urbain.

## | 5.5 Typologie et distance euclidienne


```{r croisement typologie et distance euclidienne, eval = TRUE}


disteucl <- st_read("Archives/sorties_2011-2020/disteucl.gpkg", layer = "disteucl", quiet = TRUE)

disteucl <- merge (disteucl, count_CN_typo, by = "CODGEO_2020", all.y = FALSE)


GroupesDisteucl <- by(disteucl$dist_CN, disteucl$Typomaj, mean, na.rm = TRUE)
GroupesDisteucl <- data.frame(as.table (GroupesDisteucl))
colnames(GroupesDisteucl) <- c("Typomaj", "mean")
GroupesDisteucl$sd <- as.numeric(by(disteucl$dist_CN, disteucl$Typomaj, sd, na.rm = TRUE))
GroupesDisteucl$median <- as.numeric(by(disteucl$dist_CN, disteucl$Typomaj, median, na.rm = TRUE))
# On rajoute les valeurs moyennes pour faciliter les comparaisons
levels(GroupesDisteucl$Typomaj) <- c(levels (GroupesDisteucl$Typomaj), "Ensemble")
GroupesDisteucl[ nrow(GroupesDisteucl)+1, ] <- c("Ensemble",
                                                 mean(disteucl$dist_CN, na.rm = TRUE),
                                                 sd(disteucl$dist_CN, na.rm = TRUE),
                                                 median(disteucl$dist_CN, na.rm = TRUE))
# Esthétique pour faciliter la lecture
GroupesDisteucl[, 2] <- as.numeric(GroupesDisteucl[, 2])
GroupesDisteucl[, 3] <- as.numeric(GroupesDisteucl[, 3])
GroupesDisteucl[, 4] <- as.numeric(GroupesDisteucl[, 4])
GroupesDisteucl[, 2:4] <- round(GroupesDisteucl[, 2:4], 1)

tmp <- GroupesDisteucl
colnames(tmp) <- c("Groupe majoritaire dans la commune nouvelle", "Moyenne", "Écart-type", "Médiane")
kable(tmp, row.names = F, digits = 1, caption = "Typologie et distance euclidienne intra-communes nouvelles")

condformat(tmp[, c(1,2, 4)]) %>%
          
          rule_fill_gradient2("Moyenne", low = "darkblue", high = "red", limits = c(min (tmp$Moyenne), max (tmp$Moyenne))) %>%
          rule_fill_gradient2("Médiane", low = "darkblue", high = "red", limits = c(min(tmp$Médiane), max(tmp$Médiane))) %>%
         
  theme_caption(caption = "Typologie et distance euclidienne intra-communes nouvelles") %>%
  theme_htmlWidget(number_of_entries = nrow(tmp))



```

L'observation de la distance euclidienne en fonction des catégories de communes précédemment élaborés permet de visualiser les différences entre les groupes. Les communes dont le type majoritaire est le 1 et le 2, par exemple, sont en moyenne plus homogènes que les communes nouvelles où les groupes 3, 5 et surtout 4 dominent.



## | 5.6 Typologie vis-à-vis de quelques autres données

```{r typo et surface ou pop}
# Création d'une variable surface
# Si on part de rien, jouer les deux lignes ci-dessous
# typo <- st_read("Archives/sorties_2011-2020/typo.gpkg", quiet = TRUE)
comparaisons <- data.frame( table (typo$Groupes))

# Création d'une variable de surface
typo$surface <- st_area(typo) # Attention, unités : m²
typo$surface <- set_units(typo$surface, km^2) # On passe en km²
typo$densite <- typo$P09_POP/typo$surface

comparaisons$surface_moy <- round(tapply (typo$surface, typo$Groupes, mean), 2) # On fait la moyenne de la surface
comparaisons$surface_med <- round(tapply (typo$surface, typo$Groupes, median), 2) # On fait la médiane de la surface

comparaisons$pop_moy <- round(tapply (typo$P09_POP, typo$Groupes, mean), 2) # On fait la moyenne de la population
comparaisons$pop_med <- round(tapply (typo$P09_POP, typo$Groupes, median), 2) # On fait la médiane de la population

comparaisons$dens_moy <- round(tapply (typo$densite, typo$Groupes, mean), 2) # On fait la moyenne de la population
comparaisons$dens_med <- round(tapply (typo$densite, typo$Groupes, median), 2) # On fait la médiane de la population


tmp <- comparaisons[, c("Var1", "Freq", "surface_moy", "surface_med", "pop_moy", "pop_med", "dens_moy", "dens_med")]

colnames(tmp) <- c("Groupe", "Fréquence", "Surface moyenne (km²)", "Surface médiane (km²)", "Population moyenne", "Population médiane", "Densité moyenne", "Densité médiane")

table <- condformat(tmp)%>%
          rule_fill_gradient2("Surface moyenne (km²)", low = "blue", high = "red") %>%
          rule_fill_gradient2("Surface médiane (km²)", low = "blue", high = "red") %>%
          rule_fill_gradient2("Population moyenne", low = "blue", high = "red") %>%
          rule_fill_gradient2("Population médiane", low = "blue", high = "red") %>%
          rule_fill_gradient2("Densité moyenne", low = "blue", high = "red") %>%
          rule_fill_gradient2("Densité médiane", low = "blue", high = "red") %>%
  theme_caption(caption = "Groupes de la typologie vis-à-vis de la surface et de la population des communes fusionnantes") %>%
  theme_htmlWidget(number_of_entries = nrow(tmp))
print(table)

```


```{r repartition par regions des differents types}
# On liste, pour chaque région, le nombre de communes appartenant à chaque groupe
typoregions <- data.frame(table(typo$REG, typo$Groupes))


# Import d'un fichier donnant le nom des régions en fonction de leur code : https://www.insee.fr/fr/information/2560625#titre-bloc-29
names <- data.frame(read_excel("data-raw/stats_insee/table-appartenance-geo-communes-11.xls", sheet = "Niv_supracom", skip = 5))
names <- subset(names , names$NIVGEO == "REG")
typoregions <- merge (typoregions, names[, c("CODGEO", "LIBGEO")], by.x = "Var1", by.y = "CODGEO", all.x = TRUE, all.y = FALSE)

# Pour avoir les groupes en colonnes, plus pertinent de le faire avant l'ajout des noms
typoregions1 <- dcast(typoregions, LIBGEO ~ Var2, value.var = "Freq")

# Pour avoir les régions en colonnes
typoregions2 <- dcast(typoregions, Var2 ~ LIBGEO, value.var = "Freq")


min <- min(typoregions1[, 2:ncol(typoregions1)])
max <- max(typoregions1[, 2:ncol(typoregions1)])

# Si le format choisi est avec les groupes en colonnes
table <- condformat(typoregions1) %>% # ici les couleurs sont définies par les limites min/max
          rule_fill_gradient2("Groupe 1 PPCQ", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 2 PFO", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 3 MOARO", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 4 VAR", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Groupe 5 REAV", low = "white", high = "red", limits = c(min, max))
print(table)

table2 <- condformat(typoregions1) %>% # ici les couleurs sont les min/max automatiques, par colonnes
          rule_fill_gradient2("Groupe 1 PPCQ", low = "blue", high = "red") %>%
          rule_fill_gradient2("Groupe 2 PFO", low = "blue", high = "red") %>%
          rule_fill_gradient2("Groupe 3 MOARO", low = "blue", high = "red") %>%
          rule_fill_gradient2("Groupe 4 VAR", low = "blue", high = "red") %>%
          rule_fill_gradient2("Groupe 5 REAV", low = "blue", high = "red")
print(table2)

# Si le format choisi est avec les régions en colonnes
table3 <- condformat(typoregions2) %>% # ici les couleurs sont les min/max automatiques, par colonnes
          rule_fill_gradient2("Alsace", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Aquitaine", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Auvergne", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Basse-Normandie", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Bourgogne", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Bretagne", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Centre", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Champagne-Ardenne", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Franche-Comté", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Haute-Normandie", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Île-de-France", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Languedoc-Roussillon", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Limousin", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Lorraine", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Midi-Pyrénées", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Nord-Pas-de-Calais", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Pays de la Loire", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Picardie", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Poitou-Charentes", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Provence-Alpes-Côte d'Azur", low = "white", high = "red", limits = c(min, max)) %>%
          rule_fill_gradient2("Rhône-Alpes", low = "white", high = "red", limits = c(min, max))
print(table3)

table4 <- condformat(typoregions2) %>% # ici les couleurs sont les min/max automatiques, par colonnes
          rule_fill_gradient2("Alsace", low = "white", high = "red") %>%
          rule_fill_gradient2("Aquitaine", low = "white", high = "red") %>%
          rule_fill_gradient2("Auvergne", low = "white", high = "red") %>%
          rule_fill_gradient2("Basse-Normandie", low = "white", high = "red") %>%
          rule_fill_gradient2("Bourgogne", low = "white", high = "red") %>%
          rule_fill_gradient2("Bretagne", low = "white", high = "red") %>%
          rule_fill_gradient2("Centre", low = "white", high = "red") %>%
          rule_fill_gradient2("Champagne-Ardenne", low = "white", high = "red") %>%
          rule_fill_gradient2("Franche-Comté", low = "white", high = "red") %>%
          rule_fill_gradient2("Haute-Normandie", low = "white", high = "red") %>%
          rule_fill_gradient2("Île-de-France", low = "white", high = "red") %>%
          rule_fill_gradient2("Languedoc-Roussillon", low = "white", high = "red") %>%
          rule_fill_gradient2("Limousin", low = "white", high = "red") %>%
          rule_fill_gradient2("Lorraine", low = "white", high = "red") %>%
          rule_fill_gradient2("Midi-Pyrénées", low = "white", high = "red") %>%
          rule_fill_gradient2("Nord-Pas-de-Calais", low = "white", high = "red") %>%
          rule_fill_gradient2("Pays de la Loire", low = "white", high = "red") %>%
          rule_fill_gradient2("Picardie", low = "white", high = "red") %>%
          rule_fill_gradient2("Poitou-Charentes", low = "white", high = "red") %>%
          rule_fill_gradient2("Provence-Alpes-Côte d'Azur", low = "white", high = "red") %>%
          rule_fill_gradient2("Rhône-Alpes", low = "white", high = "red") %>%
print(table4)


# On liste, pour chaque département, le nombre de communes appartenant à chaque groupe
# méthode #
dep_typo <- unique(typo$CODE_DEPT)
typodep <- data.frame()
for (i in dep_typo) {
  numero <- i
  subset <- subset (typo, CODE_DEPT == i)
  b <- table(subset$Groupes)
 resultdep <- c(numero, b)
 typodep <- rbind (typodep, resultdep, stringsAsFactors = FALSE)
 rm(numero, subset, b, resultdep)
}

# méthode 2 (revient au môme)
typodep <- data.frame(table(typo$CODE_DEPT, typo$Groupes))
typodep <- dcast(typodep, Var1 ~ Var2)


# Cartographie
dep <- merge(dep, typodep, by.x = "CODE_DEPT", by.y = "Var1", all.x = TRUE)
dep[is.na(dep)] <- 0

# Manipulation des noms de groupes car sinon variables non reconnues
NomsGroupesCAH2 <- str_replace_all(NomsGroupesCAH, " ", "_")
colnames(dep)[3:7] <- NomsGroupesCAH2

par(mfrow=c(2,3)) 
for (i in NomsGroupesCAH2) {
plot(st_geometry(dep))
propSymbolsLayer(x = dep,
                 var = i, symbols ="circle",
                 col =  "#B00EF0",
                 legend.pos = "left",
                 legend.title.txt = "Nombre de communes fusionnantes", inches = 0.2, fixmax = 150)
}

```



```{r export_typo et nettoyage fin section 5, echo = FALSE}

st_write(obj = typo, dsn = "Archives/sorties_2011-2020/typo.gpkg", layer = "typo", delete_layer = TRUE, quiet = TRUE)
rm(list=ls())
```


# 6. ANALYSES BIVARIÉES


## | 6.0 Préparation des données

```{r Prep data section 5, eval = TRUE}
geom2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2011", quiet = TRUE) # Les communes selon la géographie en vigueur au 1er janvier 2011.
geom2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2020", quiet = TRUE) # L'ensemble des communes au 01/01/2020, selon la géographie en vigueur.
# NB : dans geom 2020, les communes nouvelles ont comme caractéristiques l'addition des stock des communes qui les composent.
geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE) # Les  communes qui ont participé à la création de communes nouvelles (appelées communes fusionnantes).
geomCN2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomCN2020", quiet = TRUE) # Les  communes nouvelles, avec les géométries au 1er janvier 2020 et caractérisées par les données à la géométrie 2011 agrégées.
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE) # Départements

# Import des données
load("Archives/data_2011-2020/refdata.Rdata")


datafus2011 <- subset(df2011, COM_NOUV == "OUI") # Désigne les données concernant les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes
dataCN2020 <- subset(df2020, COM_NOUV == "OUI") # Les  communes nouvelles, avec les géométries au 1er janvier 2020 et caractérisées par les données à la géométrie 2011 agrégées.
dataNfus2011 <- subset(df2011, COM_NOUV == "NON") # Les communes, à la géométrie 2011, qui n'ont pas participé à la création d'une commune nouvelle

# Appariement des données
geom2011 <- merge(geom2011, df2011, by = "CODGEO")
geom2020 <- merge(geom2020, df2020, by = "CODGEO_2020")
geomCN2020 <- merge(geomCN2020, dataCN2020, by = "CODGEO_2020")
geomfus2011 <- merge(geomfus2011, datafus2011, by = "CODGEO")

# Définition de sous-ensembles
testEdC <- subset (geom2011, CODGEO_2020 == "61324" | CODGEO_2020 =="73150" | CODGEO_2020 == "73006")
testEdCSavoie <- subset (geom2011, CODGEO_2020 =="73150" | CODGEO_2020 == "73006")
testNormandie <- subset (geom2011, REG == "23" | REG == "25")
test49 <- subset (geom2011, CODE_DEPT == "49" )
testOuest <- subset (geom2011, REG == "23" | REG == "25"| REG == "53"| REG == "52") # Normandies, Bretagne, Pays-de-la-Loire

# Import des données de la typologie
typo <- st_read("Archives/sorties_2011-2020/typo.gpkg", quiet = TRUE)

```


## | 6.1 Croisement de la typologie avec d'autres variables

```{r Croisement typologie et autres variables}

Y <- typo$P11_POT_FIN / typo$P09_POP
Y [1:10]
# Pour variables qualitatives
summary(Y)
Y<-cut(Y,breaks=c(quantile(Y)))
levels(Y)<-c("Q1","Q2", "Q3", "Q4")
Y [1:10]
X<-typo$Groupes
X [1:10]

tabcont<-table(X,Y)
tabcont # En valeur absolue
# round(100*prop.table(tabcont,margin=1),1) # Pourcentages, le total se fait par lignes
# round(100*prop.table(tabcont,margin=),1) # Pourcentages, le total se fait sur l'ensemble de la population
# round(100*prop.table(tabcont,margin=2),1) # Pourcentages, le total se fait par colonnes

```


## | 6.2 Test du Chi-2 



```{r Test chi-2, eval = FALSE}
Y <- testOuest$FUSION
# Pour variables qualitatives
summary(Y)
# Y<-cut(Y,breaks=c(quantile(Y)))
# levels(Y)<-c("Q1","Q2", "Q3", "Q4")
X <- testOuest$C09_ACTOCC

head(testOuest)

summary(X)
tabcont<-table(X,Y)
tabcont # En valeur absolue
# round(100*prop.table(tabcont,margin=1),1) # Pourcentages, le total se fait par lignes
# round(100*prop.table(tabcont,margin=),1) # Pourcentages, le total se fait sur l'ensemble de la population
# round(100*prop.table(tabcont,margin=2),1) # Pourcentages, le total se fait par colonnes


test<-chisq.test(tabcont)
test$observed
round(test$expected,1)
round(test$residuals,2)
test

```



```{r Nettoyage espace de travail fin section 6, echo = FALSE}
rm(list=ls())
```


# 7 - ÉTUDE DES NAVETTES

Nous l'avons vu, les communes fusionnantes sont marquées, plus que l'ensemble des communes françaises, par le phénomène de "migrations pendulaires" ou "navettes domicile-travail" intercommunales : la commune de résidence n'est pas la commune de travail. Il est, par conséquent, important de s'attarder sur ce point.

Les communes nouvelles constituent, de fait, des ensembles statistiques nouveaux. Leur périmètre est parfois présenté comme plus cohérent au vu des territoires vécus, par exemple concernant les flux domicile-travail. Il est intéressant de comparer cet argument rarement chiffré aux données de l'INSEE concernant les migrations pendulaires.


## | 7.0 Préparation des données

```{r Prep data section 6, eval = TRUE}
geom2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2011", quiet = TRUE) # Les communes selon la géographie en vigueur au 1er janvier 2011.
load("Archives/data_2011-2020/refdata.Rdata")
rm(df2020)
df2011 <- df2011[, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "CATAEU2010", "FusPhas", "COM_NOUV", "FUSION", "P09_POP", "REG", "CODE_DEPT")]
geom2011 <- merge(geom2011, df2011, by = "CODGEO")
```

## | 7.1 Données et méthodes utilisées pour l'étude des navettes

L'INSEE fournit de nombreux fichiers concernant les navettes, disponibles ici : https://www.insee.fr/fr/statistiques/2022117.
L'ensemble des données ne sont présentes que dans le document `BTT_FM_DTR_2009.txt` (le fichier `BTT_FM_DTR_2009.xls` ne comprend que les flux supérieurs à 100 unités ou les données concernant le nombre de navetteurs pour une commune donnée). Dans ce fichier, chaque flux est défini par sa commune de départ, sa commune d'arrivée et son volume (nombre de navetteurs).
Il s'agit des données 2009, à la géographie en vigueur au 1er janvier 2011. Les métadonnées sont précisées dans le fichier `BTX_FM_DTR_2009.xls.`

```{r Import data flux domicile-travail, eval = TRUE}
# Import de l'intégralité des flux
NavettesToutes <- read.csv2("data-raw/Flux_domicile_travail/BTT_FM_DTR_2009.txt", stringsAsFactors=TRUE)

```


Pour exploiter ces données, nous nous sommes appuyés sur le package `flows`, dont la démarche est présentée ici (https://cran.r-project.org/web/packages/flows/vignettes/flows.html) (@giraud2016) et là (https://journals.openedition.org/netcom/2134) (@beauguitte2015).


```{r Import et choix data, eval = TRUE}
# On choisit les données qu'on veut étudier pour les CN enquêtées
nav <- NavettesToutes

# Pour ne prendre que les communes enquêtées en Savoie (le traitement total est trop lourd)
nav <- subset(NavettesToutes, CODGEO == "73006" | DCLT == "73006" 
              | CODGEO == "73038" | DCLT == "73038" | CODGEO == "73093" | DCLT == "73093"
              | CODGEO == "73126" | DCLT == "73126" | CODGEO == "73150" | DCLT == "73150"
              | CODGEO == "73169" | DCLT == "73169" | CODGEO == "73305" | DCLT == "73305")

# Préparation des données pour qu'elles soient adaptées au package
nav$CODGEO <- as.character(nav$CODGEO)
nav$DCLT <- as.character(nav$DCLT)
nav$L_DCLT <- as.character(nav$L_DCLT)

myflows <- prepflows(mat = nav, i = "CODGEO", j = "DCLT", fij = "NBFLUX_C09_ACTOCC15P")
myflows[1:4,1:4]
diag(myflows) <- 0

```

## | 7.2 Premiers aperçus des flux

```{r Premiers aperçus des flux, out.width='100%'}
str(nav)
# Affichage de graphiques
statmat(mat = myflows, output = "all", verbose = FALSE)
# Affichage de statistiques
statmat(mat = myflows, output = "none", verbose = TRUE)
```

## | 7.3 Sélection de certains flux

Grâce au package flows, plusieurs fonctions permettent de sélectionner certains flux. Parmi ces fonctions, On peut utiliser :
- nfirst: sélectionne les k premiers flux de toutes les origines;
- xfirst: sélectionne tous les flux supérieurs à un seuil k;
- xsumfirst: sélectionne autant de flux que nécessaire pour chaque origine afin que leur somme soit au moins égale à k.

```{r Choix de certains flux}
# Sélection des premiers flux
flowSel1 <- firstflows(mat = myflows, method = "nfirst", ties.method = "first",
                       k = 1)
# Selection des flux > 500
flowSel1 <- firstflowsg(mat = myflows, method = "xfirst", k = 5)

# Sélection à partir de plusieurs conditions
# Sélection des flux qui représentent au moins 20% des départs de la commune
flowSel1 <- firstflows(mat = myflows/rowSums(myflows)*100, method = "xfirst", k = 1)
# Applique le 2e critère de Nystuen et Dacey (1961) :
# On garde le flux fij si la somme des flux reçus par j est supérieure à la somme des flux reçus par i.
# Sinon, on garde le flux fji.
flowSel2 <- domflows(mat = myflows, w = colSums(myflows), k = 1)

# On multiplie pour obtenir uniquement les flux souhaités (flowSel 1 et 2 sont binaires)
flowSel <- myflows * flowSel1 * flowSel2

# Si on souhaite prendre tous les flux
flowSel <- myflows 

# Comparaison de la matrice initiale et de la matrice avec les flux sélectionnés
compmat(mat1 = myflows, mat2 = myflows * flowSel, digits = 1)

```

## | 7.4 Calculs des départs/arrivées totaux et de quelques indicateurs

Sur les indicateurs calculés, cf. http://grasland.script.univ-paris-diderot.fr/agreg/module6/index.html

```{r Calculs de quelques indicateurs}
inflows <- data.frame(id = colnames(flowSel), w = colSums(flowSel))
outflows <- data.frame(id = rownames(flowSel), w = apply(flowSel, 1, sum))

# Attention, ne prennent en compte que les flux entrant ou sortant des communes sélectionnées
FluxTotaux <- merge(inflows, outflows, by = "id", all.x = TRUE)
navNames <- unique(NavettesToutes[, c("DCLT", "L_DCLT")])
FluxTotaux <- merge(FluxTotaux, navNames, by.x = "id", by.y = "DCLT", all.x = TRUE)
colnames(FluxTotaux)[2] <- "Arrivées"
colnames(FluxTotaux)[3] <- "Départs"


FluxTotaux$Volume <- FluxTotaux$Arrivées + FluxTotaux$Départs
FluxTotaux$Solde <- FluxTotaux$Arrivées - FluxTotaux$Départs
FluxTotaux$Attractivité <- FluxTotaux$Solde / FluxTotaux$Volume
```

## | 7.5 Introduction aux pôles dominants/intermédiaires/dominés

```{r Cartographie Dominant/Intermediary/Dominated, eval = TRUE}

# Transformation des géométries en un spdf utilisable pour la cartographie
ShpCommunes2011 <- as(geom2011, "Spatial")

# Que Passais-Villages
ShpEdC <- subset(ShpCommunes2011, CODGEO_2020 == "61324")
ShpEdC <- subset(ShpCommunes2011, CODE_DEPT == "61" | CODE_DEPT == "53")

# Que Savoie
ShpEdC <- subset(ShpCommunes2011, CODGEO_2020 =="73150" | CODGEO_2020 == "73006")

# rm(ShpCommunes2011)

sp::plot(ShpEdC, col = "#cceae7")
plotMapDomFlows(mat = flowSel, spdf = ShpEdC, spdfid = "CODGEO", w = inflows, wid = "id",
                wvar = "w", wcex = 0.05, add = TRUE,
                legend.flows.pos = "topright",
                legend.flows.title = "Nb. of commuters")
title("Dominant Flows of Commuters")
mtext(text = "INSEE, 2011", side = 4, line = -1, adj = 0.01, cex = 0.8)

```


Le package `flows` propose de catégoriser les entités en pôles dominants/intermédiaires/dominés. Ils sont définis selon les règles suivantes :
(1) le flux le plus important de i est émis en direction de j ;
(2) la somme des flux reçus par j est supérieure à la somme des flux reçus par i.
- i est dominé si son flux le plus important est émis vers j qui reçoit un volume de flux plus important que lui.
- j est intermédiaire si son flux le plus important est émis vers k qui reçoit un volume de flux plus important que lui et que, par ailleurs, il domine i.
- k est dominant si son flux le plus important est vers un nœud qui reçoit un volume de flux moins important que lui.

```{r Extraction des informations concernant Dominant/Intermediary/Dominated}

# Ce script donne la liste des unités appartenant à chacune des catégories.
# https://gist.github.com/rCarto/f06aabf2852e4a9b8ba51e93c17eb5f6

Dominated <- colnames(flowSel)[colSums(flowSel) == 0]
Dominant <- rownames(flowSel)[rowSums(flowSel) == 0]
Intermediary <- rownames(flowSel)[!rownames(flowSel) %in% c(Dominant, Dominated)]
head(Dominated)
head(Intermediary)
head(Dominant)
# Pour cartographie
# labelLayer(spdf = ShpEdC[ShpEdC@data$CODGEO %in% Dominated,], txt = "CODGEO", col= "red")
# labelLayer(spdf = ShpEdC[ShpEdC@data$CODGEO %in% Dominant,], txt = "CODGEO", col= "blue")
# labelLayer(spdf = ShpEdC[ShpEdC@data$CODGEO %in% Intermediary,], txt = "CODGEO", col= "green")


```



## | 7.6 Catégorisation de toutes les communes fusionnantes (par itérations successives)

Nous souhaitons observer la composition des communes nouvelles du point de vue de cette catégorisation en pôles dominants/intermédiaires/dominés.

### || 7.6.0 Liste des tests effectues
xfirst5_domflows1 : On sélectionne tous les flux supérieurs à 5 personnes
xfirst50pct_domflows1 : On sélectionne tous les flux représentant au moins 50% des navetteurs 
xfirst20pct_domflows1 : On sélectionne tous les flux représentant au moins 20% des navetteurs 
nfirst
sumfirst60_domflows1 : On sélectionne tous les flux pour que leur addition représente au moins 60 % des flux.

### || 7.6.1 Description de toutes les communes fusionnantes

```{r Analyse de toutes les communes fusionnantes, eval = FALSE}

# Import pour lancer rapidement les tests

geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE) # Les  communes qui ont participé à la création de communes nouvelles (appelées communes fusionnantes).
load("Archives/data_2011-2020/refdata.Rdata")

df2011 <- df2011[, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "COM_NOUV")]
datafus2011 <- subset(df2011, COM_NOUV == "OUI") # Désigne les données concernant les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes
geomfus2011 <- merge(geomfus2011, datafus2011, by = "CODGEO")
NavettesToutes <- read.csv2("data-raw/Flux_domicile_travail/BTT_FM_DTR_2009.txt", stringsAsFactors=TRUE)


# Définition d'un vecteur avec les identifiants des communes nouvelles
mesCommunes <- unique(datafus2011$CODGEO_2020)

df <- NavettesToutes
# Création d'un champs indiquant si la commune origine appartient à une commune nouvelle
df <- merge(df, datafus2011[, c("CODGEO", "CODGEO_2020")], by = "CODGEO", all.x = TRUE)
# Création d'un champs indiquant si la commune destination appartient à une commune nouvelle
df <- merge(df, datafus2011[, c("CODGEO", "CODGEO_2020")], by.x = "DCLT", by.y = "CODGEO", all.x = TRUE)
# Adaptation des données au package flows
df$CODGEO <- as.character(df$CODGEO)
df$DCLT <- as.character(df$DCLT)
df$L_DCLT <- as.character(df$L_DCLT)
rm(NavettesToutes, geomfus2011) # Supprimer les objets pour alléger R


results <- data.frame()

for (i in mesCommunes) { # Pour chaque identifiant de commune nouvelle, 
  nav1 <- subset (df, CODGEO_2020.x == i | CODGEO_2020.y == i ) # Ne garder que navettes partant ou arrivant des communes fusionnantes y ayant participé
  listeCommunes <- c(unique(nav1$DCLT), unique(nav1$CODGEO)) # On prélève les identifiants des communes concernées
  listeCommunes <- unique(listeCommunes) # En supprimant les doubles comptes
  compil_Navettes <- data.frame(matrix(ncol=7, nrow=0))
  
  for (z in listeCommunes) { # Pour chaque commune qui apparaît en source ou destination d'une des communes fusionnantes
    nav2 <- subset (df, DCLT == z) # On intègre tous ses flux...
    compil_Navettes <- rbind(compil_Navettes, nav2) #... dans un tableau...
  }
  
  nav <- unique(compil_Navettes) #... dont on supprime les doubles comptes
  myflows <- prepflows(mat = nav, i = "CODGEO", j = "DCLT", fij = "NBFLUX_C09_ACTOCC15P")
  diag(myflows) <- 0
  flowSel1 <- firstflows(mat = myflows/rowSums(myflows)*100, method = "xfirst", k = 5)
  

  flowSel2 <- domflows(mat = myflows, w = colSums(myflows), k = 1)
    # On multiplie pour obtenir uniquement les flux souhaités (flowSel 1 et 2 sont binaires)
  flowSel <- myflows * flowSel1 * flowSel2
  
  # flowSel <- myflows # Possibilité de sélectionner ?
  Dominated <- colnames(flowSel)[colSums(flowSel) == 0]
  Dominant <- rownames(flowSel)[rowSums(flowSel) == 0]
  Intermediary <- rownames(flowSel)[!rownames(flowSel) %in% c(Dominant, Dominated)]
  
  resultspartiels <- subset(datafus2011[, c("CODGEO", "CODGEO_2020")], CODGEO_2020 == i) # Pour toutes les communes fusionnantes appartenant à la commune nouvelle étudiée (i), on note si elle est dominante, dominée ou intermédiaire
  resultspartiels$StatutNavettes[resultspartiels$CODGEO %in% Dominated] <- "Dominated"
  resultspartiels$StatutNavettes[resultspartiels$CODGEO %in% Dominant] <- "Dominant"
  resultspartiels$StatutNavettes[resultspartiels$CODGEO %in% Intermediary] <- "Intermediary"
  results <- rbind(results,resultspartiels) # Combiner les résultats, par lignes
  
  rm(resultspartiels, nav, nav1, nav2, compil_Navettes, myflows, flowSel, flowSel1, flowSel2, listeCommunes, Dominant, Dominated, Intermediary)
  
}

write.table(results, "Archives/sorties_2011-2020/export_results_flows_xfirst5pct_domflows1.txt", sep="\t", row.names=FALSE)


```

### || 7.6.2 Synthèse par commune nouvelle


```{r Réalisation tableau synth, eval = FALSE}

# Import pour lancer rapidement les tests
geomfus2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomfus2011", quiet = TRUE) # Les  communes qui ont participé à la création de communes nouvelles (appelées communes fusionnantes).
datafus2011 <- st_set_geometry(geomfus2011, NULL)

test <- 
  # "xfirst5_domflows1" # Flux supérieurs à 5 navetteurs
  # "xfirst50pct_domflows1" # Flux représentant au moins 50% des navetteurs
  # "xfirst20pct_domflows1" # Flux représentant au moins 20% des navetteurs
  # "xfirst10pct_domflows1" # Flux représentant au moins 10% des navetteurs
  "xfirst05pct_domflows1" # Flux représentant au moins 05% des navetteurs
  # "nfirst2_domflows1" # Deux premiers flux
  # "nfirst5_domflows1" # Cinq premiers flux
  # "nfirst10_domflows1" # Dix premiers flux
  # "sumfirst60_domflows1" # Flux pour que leur addition représente au moins 60 % des flux.
ResultsFlux <- read.table(paste0("Archives/sorties_2011-2020/export_results_flows_", test, ".txt"), # Test 0
                           sep="\t", colClasses = "character", head = TRUE, stringsAsFactors = TRUE)


mesCommunes <- unique(ResultsFlux$CODGEO_2020)

results <- data.frame() # On prépare le tableau avec les résultats

for (i in mesCommunes) { # Pour chaque identifiant de commune nouvelle, 
  Pranalyse <- subset(ResultsFlux, CODGEO_2020 == i) # On extrait les données concernant les communes fusionnantes d'une CN
  a <- sum(Pranalyse$StatutNavettes %in% "Dominant") # Nombre de pôles dominants dans la commune nouvelle
  b <- sum(Pranalyse$StatutNavettes %in% "Intermediary") # Nombre de pôles intermédiaires dans la commune nouvelle
  c <- sum(Pranalyse$StatutNavettes %in% "Dominated") # Nombre de pôles dominés dans la commune nouvelle
  d <- Pranalyse$StatutNavettes[Pranalyse$CODGEO == Pranalyse$CODGEO_2020]

  resultspartiels <- c(i, a, b, c, d)
  results <- rbind(results,resultspartiels, stringsAsFactors= FALSE) # Combiner les résultats, par lignes
  
  rm(i, Pranalyse, a, b, c, d, resultspartiels)
  
}
colnames(results) <- c("CODGEO_2020", "NbrDominant", "NbrIntermediary", "NbrDominated", "StatutChefLieu")


write.table(results, paste0("Archives/sorties_2011-2020/Synthese_Dominants_", test, ".txt"), sep="\t", row.names=FALSE)  
```

### || 7.6.3 Le statut des communes fusionnantes et des chefs-lieux

```{r Pour sortie des types des chefs-lieux, eval = TRUE}
test <- 
  # "xfirst5_domflows1" # Flux supérieurs à 5 navetteurs
  # "xfirst50pct_domflows1" # Flux représentant au moins 50% des navetteurs
  # "xfirst20pct_domflows1" # Flux représentant au moins 20% des navetteurs
  # "xfirst10pct_domflows1" # Flux représentant au moins 10% des navetteurs
  "xfirst05pct_domflows1" # Flux représentant au moins 05% des navetteurs
  # "nfirst2_domflows1" # Deux premiers flux
  # "nfirst5_domflows1" # Cinq premiers flux
  # "nfirst10_domflows1" # Dix premiers flux
  # "sumfirst60_domflows1" # Flux pour que leur addition représente au moins 60 % des flux.

ResultsSynth <- read.table(paste0("Archives/sorties_2011-2020/Synthese_Dominants_", test, ".txt"),
                           sep="\t", colClasses = "character",
                           head = TRUE, stringsAsFactors = TRUE)


ResultsSynth[,2] <- as.numeric(ResultsSynth[,2])
ResultsSynth[,3] <- as.numeric(ResultsSynth[,3])
ResultsSynth[,4] <- as.numeric(ResultsSynth[,4])
ResultsSynth$StatutChefLieu <- as.factor(ResultsSynth$StatutChefLieu)

summary(ResultsSynth)
kable(apply(ResultsSynth[, 2:4], 2, sum))
sum(apply(ResultsSynth[, 2:4], 2, sum)
)
kable(summary(ResultsSynth$StatutChefLieu), col.names = "Statut des communes chef-lieu", caption = paste0 ("Critère de sélection des flux : ", test))


```


Le premier élément que nous livre cette analyse est que les communes nouvelles ne sont pas constituées autour de pôles majeurs mais plutôt de pôles secondaires. Les communes qui fusionnent ne sont pas toutes avec le même statut. À partir de la catégorisation des communes en pôles dominés, dominants ou intermédiaires, on s'aperçoit tout d'abord qu'un nombre très faible (29) de communes fusionnantes sont des pôles dominants. Davantage sont des pôles dominés (198) mais la très grande majorité sont des pôles intermédiaires. Cela va dans le sens de communes qui ne seraient pas des territoires complètement marginalisés et exclues des circulations, mais plutôt des relais rarement majeurs mais pas pour autant négligeables.


### || 7.6.4 Cartographie des pôles ainsi obtenus

```{r Carto Synth poles, eval = FALSE}
test <- # Choix des flux sélectionnés
  "xfirst05pct_domflows1" # Flux représentant au moins 5 % des navetteurs 
  # "xfirst5_domflows1" # Flux supérieurs à 5 navetteurs
  # "xfirst50pct_domflows1" # Flux représentant au moins 50% des navetteurs 
  # "xfirst20pct_domflows1" # Flux représentant au moins 20% des navetteurs 
  # "sumfirst60_domflows1" # Flux pour que leur addition représente au moins 60 % des flux.

ResultsSynth <- read.table(paste0("Archives/sorties_2011-2020/Synthese_Dominants_", test, ".txt"), # Test 0
                           sep="\t", colClasses = "character", head = TRUE, stringsAsFactors = TRUE)
ResultsSynth$StatutChefLieu <- as.factor(ResultsSynth$StatutChefLieu)
levels(ResultsSynth$StatutChefLieu)
geomCN2020 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geomCN2020", quiet = TRUE)  
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE) # Départements

ResultsSynth <- merge(geomCN2020, ResultsSynth, by = "CODGEO_2020")
par(mfrow = c(1, 1))
par(mar=c(0,0,1.2,0))
plot(st_geometry(dep), border = "#1A1A19",lwd = 1)

typoLayer(x = ResultsSynth, var = "StatutChefLieu",  
          col = c("#377eb8","#4daf4a","#e41a1c"),
          border = NA, 
          legend.title.cex = 0.7,
          legend.values.cex = 0.6,
          legend.values.order = c("Dominated", "Intermediary", "Dominant"),
          legend.pos = "left", add = T)

layoutLayer(title = paste0("Statut du chef-lieu des communes nouvelles\ndu point de vue des navettes quotidiennes", "\n[Critère : ", test, "]"),
            author = "G. Bideau, R. Ysebaert, 2021.",
            tabtitle = TRUE, frame = FALSE, col = "white", coltitle = "black",
            sources = "Sources : INSEE, IGN, 2020.")
```


### || 7.6.5 Les statuts des chefs-lieux en fonction des flux sélectionnés
Liste des différents résultats en fonction des seuils retenus concernant le statut des chefs-lieux


```{r Pour sortie des statuts des chefs-lieux en fonction de differents criteres, eval = TRUE}
listetests <- c(
  "xfirst5_domflows1" # Flux supérieurs à 5 navetteurs
 , "xfirst50pct_domflows1" # Flux représentant au moins 50% des navetteurs
 , "xfirst20pct_domflows1" # Flux représentant au moins 20% des navetteurs
 , "xfirst10pct_domflows1" # Flux représentant au moins 10% des navetteurs
 , "xfirst05pct_domflows1" # Flux représentant au moins 05% des navetteurs
 , "nfirst2_domflows1" # Deux premiers flux
 , "nfirst5_domflows1" # Cinq premiers flux
 , "nfirst10_domflows1" # Dix premiers flux
 # , "sumfirst60_domflows1" # Flux pour que leur addition représente au moins 60 % des flux.
)

tableau <- data.frame()
for (i in listetests) {
ResultsSynth <- read.table(paste0("Archives/sorties_2011-2020/Synthese_Dominants_", i, ".txt"),
                           sep="\t", colClasses = "character",
                           head = TRUE, stringsAsFactors = TRUE)

ResultsSynth[,2] <- as.numeric(ResultsSynth[,2])
ResultsSynth[,3] <- as.numeric(ResultsSynth[,3])
ResultsSynth[,4] <- as.numeric(ResultsSynth[,4])
ResultsSynth$StatutChefLieu <- as.factor(ResultsSynth$StatutChefLieu)

a <- summary(ResultsSynth$StatutChefLieu)
resultpartiel <- c(i, a)
tableau <- rbind (tableau, resultpartiel, stringsAsFactors = FALSE)
rm(a, resultpartiel)

}
colnames(tableau) <- c("Critère de sélection des flux", "Pôle dominant", "Pôle dominé", "Pôle intermédiaire")
kable(tableau)


```


## | 7.7 Premiers flux de navetteurs et communes nouvelles
Les communes fusionnent-elles avec celles avec lesquelles elles échangent le plus ?

Observons, pour une commune donnée, le principal flux de navetteur. La question que nous nous posons est de savoir si ce flux principal est, pour les communes fusionnantes, plutôt en direction d'une autre commune fusionnante appartenant à la même commune nouvelle ou non.
Il est important de préciser qu'on ne regarde là que le flux le plus important, ce qui peut comporter un certain nombre de biais quand ce flux le plus important ne domine les autres que de peu.

### || 7.7.1 Calcul des premiers flux

```{r Fusions et premier flux, eval = FALSE}
df <- NavettesToutes
df$CODGEO <- as.character(df$CODGEO)
df$DCLT <- as.character(df$DCLT)
# On enlève les flux d'une commune vers elle-même (les diagonales de la matrice de flux)
df <- subset(df, df$CODGEO != df$DCLT)

mesCommunes <- unique(df$CODGEO)

# On recherche, pour une commune fusionnante, la destination la plus importante
# Création du tableau de résultats
Results <- data.frame()

for (i in mesCommunes) { # Pour chaque identifiant des communes nouvelles sélectionnées 
  dfextrait <- subset (df, CODGEO == i)# extraire les données d'une commune
  a <- which.max(dfextrait$NBFLUX_C09_ACTOCC15P) # Renvoie le numéro de la ligne ayant le flux maximal
  b <- dfextrait$DCLT[a] # Renvoie l'identifiant de la destination correspondant à cette ligne
  Dest <- c(i,b)
  Results <- rbind(Results, Dest, stringsAsFactors= FALSE) # Combiner les résultats, par lignes
  rm(a)
  rm(dfextrait)
  rm(b)
  }


# Clarification des résultats
colnames(Results) <- c("CODGEO", "DestinationMax")
# Création d'un champs indiquant le référence si la commune origine appartient à une commune nouvelle
Results <- merge(Results, df2011[, c("CODGEO", "LIBGEO","CODGEO_2020", "LIBGEO_2020", "ChefLieu")], by = "CODGEO", all.x = TRUE)
# Création d'un champs indiquant la référence si la commune destination appartient à une commune nouvelle
Results <- merge(Results, df2011[, c("CODGEO", "LIBGEO", "CODGEO_2020", "LIBGEO_2020", "ChefLieu")], by.x = "DestinationMax", by.y = "CODGEO", all.x = TRUE)
Results <- Results[, c("CODGEO", "LIBGEO.x", "CODGEO_2020.x", "LIBGEO_2020.x", "ChefLieu.x", "DestinationMax", "LIBGEO.y", "CODGEO_2020.y", "LIBGEO_2020.y", "ChefLieu.y")]

write.table(Results, "Archives/sorties_2011-2020/export_results_premiersflux.txt", sep="\t", row.names=FALSE)  

```

### || 7.7.2 Analyse


```{r Analyse des premiers flux, eval = TRUE}
Results <- read.table("Archives/sorties_2011-2020/export_results_premiersflux.txt", sep="\t",
                       colClasses = "character", head = TRUE, stringsAsFactors = TRUE)
load("Archives/data_2011-2020/refdata.Rdata")
rm(df2020)
Results <- merge (Results, df2011 [, c("CODGEO", "FUSION")], by = "CODGEO") # On indique si la commune d'origine est une commune fusionnante.
Results <- merge (Results, df2011 [, c("CODGEO", "FUSION")], by.x = "DestinationMax", by.y = "CODGEO") # On indique si la commune d'arrivée est une commune fusionnante.


# On liste les communes en fonction de leur flux principal :
# Si l'origine et le départ sont des CN, est-ce la même ou non
Results$DestMaxEst <- ifelse(Results$CODGEO_2020.x == Results$CODGEO_2020.y, "Même_CN", "AutreCN")
Results$DestMaxEst[Results$FUSION.x == "NON"] <- "Origine_non_CN" # Si la commune de départ n'est pas une CN
Results$DestMaxEst[Results$FUSION.y == "NON"] <- "Dest_non_CN" # Si la commune d'arrivée n'est pas une CN
Results$DestMaxEst[Results$FUSION.x == "NON" & Results$FUSION.y == "NON"] <- "Pas_de_CN" # Si ni celle de départ ni celle d'arrivée ne sont des CN

# Simplification du tableau
tmp <- Results[, c("CODGEO", "CODGEO_2020.x", "FUSION.x", "DestinationMax", "CODGEO_2020.y", "FUSION.y", "DestMaxEst")]

# Affichage des résultats
Results$DestMaxEst <- as.factor(Results$DestMaxEst)
summary(Results$DestMaxEst)
summary(Results$DestMaxEst) * 100 / nrow(Results) # En pourcentages

# Pour faire des tests dans des sous-ensembles
ResultsComFus <- subset(Results, FUSION.x == "OUI")
summary(ResultsComFus$DestMaxEst)
summary(ResultsComFus$DestMaxEst) * 100 / nrow(ResultsComFus) # En pourcentages

ResultsComFusChefLieu <- subset(Results, FUSION.x == "OUI" & ChefLieu.x == "O")
summary(ResultsComFusChefLieu$DestMaxEst)
summary(ResultsComFusChefLieu$DestMaxEst) * 100 / nrow(ResultsComFusChefLieu) # En pourcentages

ResultsComFusNonChefLieu <- subset(Results, FUSION.x == "OUI" & ChefLieu.x == "N")
summary(ResultsComFusNonChefLieu$DestMaxEst)
summary(ResultsComFusNonChefLieu$DestMaxEst) * 100 / nrow(ResultsComFusNonChefLieu) # En pourcentages

```

### || 7.7.3 Sortie tableau

```{r Sortie tableau 1e destination rbind, eval = TRUE}
# Réalisation d'un tableau synthétique
tableau <- rbind(
  table(Results$DestMaxEst),
  table(Results$DestMaxEst) * 100 / nrow(Results),
  table(ResultsComFus$DestMaxEst),
  table(ResultsComFus$DestMaxEst) * 100 / nrow(ResultsComFus),
  table(ResultsComFusChefLieu$DestMaxEst),
  table(ResultsComFusChefLieu$DestMaxEst) * 100 / nrow(ResultsComFusChefLieu),
  table(ResultsComFusNonChefLieu$DestMaxEst),
  table(ResultsComFusNonChefLieu$DestMaxEst) * 100 / nrow(ResultsComFusNonChefLieu)
                 )
tableau <- as.data.frame (tableau)


colnames(tableau) <- c("Destination : autre commune nouvelle", "Destination : non commune nouvelle", "Destinaton : même commune nouvelle", "Origine non commune nouvelle", "Origine et destination non communes nouvelles")
tableau$Unité <- c("Nombre", "Pourcentage (%)", "Nombre", "Pourcentage (%)", "Nombre", "Pourcentage (%)", "Nombre", "Pourcentage (%)")
# On ré-ordonne le tableau pour plus de cohérence
tableau <- tableau[, c("Unité", "Destinaton : même commune nouvelle", "Destination : autre commune nouvelle", "Destination : non commune nouvelle", "Origine non commune nouvelle", "Origine et destination non communes nouvelles")]

# Nom de colonnes pour export avec kable
colnames(tableau) <- c("Origine : ", " autre commune nouvelle", " non commune nouvelle", " même commune nouvelle", "Origine non commune nouvelle", "Origine et destination non communes nouvelles")


# Sortie tableau utile
kable(tableau [, 1:4], row.names = FALSE, digits = 0, format = "html") %>%
  kableExtra::add_header_above(c(" " = 1, "Destination" = 3))%>%
  kableExtra::pack_rows(index = c(
    "ensemble des communes françaises" = 2,
    "communes fusionnantes" = 2,
    "communes fusionnantes devenues chef-lieu" = 2,
    "communes fusionnantes non chef-lieu" = 2)) 


```
Le flux le plus important d'une commune fusionnante est, dans 378 cas (15 %), une commune appartenant à la même commune nouvelle, dans 321 cas (13 %), une autre commune nouvelle et dans 1803 cas (72 %), une autre commune, hors commune nouvelle. Ces éléments montrent, dans un premier temps, que les différences entre territoires pratiqués quotidiennement et territoires communaux ne se réduisent pas de manière drastique.
La comparaison des statistiques entre les communes devenant chef-lieux (ont à 1,9 % leur premier flux vers la même commune nouvelle) et les autres communes fusionnantes (21 % ont leur premier flux vers la même commune nouvelle) nous renseigne sur la pôlarisation que peuvent exercer les communes chef-lieux qui, visiblement, attirent un nombre conséquent de flux mais sont, elles, plus souvent tournées vers une autre commune pour leur flux principal.
Si on excepte donc le cas des communes chefs-lieux, on observe néanmoins que le pourcentage de communes fusionnantes orientant leur premier flux vers la commune nouvelle concernée reste relativement faible (21 %).


```{r Sortie tableau première destination cbind, eval = FALSE, echo = FALSE}
# Réalisation d'un tableau synthétique
tableau <- cbind(
  table(Results$DestMaxEst),
  table(Results$DestMaxEst) * 100 / nrow(Results),
  table(ResultsComFus$DestMaxEst),
  table(ResultsComFus$DestMaxEst) * 100 / nrow(ResultsComFus),
  table(ResultsComFusChefLieu$DestMaxEst),
  table(ResultsComFusChefLieu$DestMaxEst) * 100 / nrow(ResultsComFusChefLieu),
  table(ResultsComFusNonChefLieu$DestMaxEst),
  table(ResultsComFusNonChefLieu$DestMaxEst) * 100 / nrow(ResultsComFusNonChefLieu)
                 )
colnames(tableau) <- c("Première destination des communes", 
                       "Première destination des communes (%)", 
                       "Première destination des communes fusionnantes", 
                       "Première destination des communes fusionnantes (%)", 
                       "Première destination des communes fusionnantes devenues chef-lieu", 
                       "Première destination des communes fusionnantes devenues chef-lieu (%)", 
                       "Première destination des communes fusionnantes non chef-lieu", 
                       "Première destination des communes fusionnantes non chef-lieu (%)"
                       )

colnames(tableau) <- c("Valeur absolue", "Pourcentages","Valeur absolue", "Pourcentages","Valeur absolue", "Pourcentages","Valeur absolue", "Pourcentages")
tableau <- as.data.frame (tableau)
kable(tableau, row.names = TRUE) %>%
  kableExtra::add_header_above(c(
    "Première destination",
    "de l'ensemble des communes françaises" =2,
    "des communes fusionnantes" = 2,
    "des communes fusionnantes devenues chef-lieu" = 2,
    "des communes fusionnantes non chef-lieu" = 2))


pack_rows(
  index = c("setosa" = 2, "versicolor" = 4, "virginica" = 3)
)
```



## | 7.8 L'indice d'attractivité
### || 7.8.1 Calcul de l'indice

Le calcul de l'indice d'attractivité nécessite d'avoir la totalité des flux entrant et des flux sortant.
Nous ne disposions pas de cet indicateur dans le fichier regroupant toutes les navettes.

```{r Calcul indice attract en partant des Navettes totales, eval = FALSE}
load("Archives/data_2011-2020/refdata.Rdata")
rm (df2020)
df2011 <- df2011[, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "CATAEU2010", "FusPhas", "COM_NOUV", "FUSION", "P09_POP", "REG")]



testEdC <- subset (df2011, CODGEO_2020 == "61324" | CODGEO_2020 =="73150" | CODGEO_2020 == "73006")
testEdCSavoie <- subset (df2011, CODGEO_2020 =="73150" | CODGEO_2020 == "73006")
testNormandie <- subset (df2011, REG == "23" | REG == "25")
NavettesToutes <- read.csv2("data-raw/Flux_domicile_travail/BTT_FM_DTR_2009.txt", stringsAsFactors=TRUE)

# Définition d'un vecteur comportant les identifiants des communes à tester
mesCommunes <- df2011$CODGEO

df <- NavettesToutes
# Adaptation des données au package flows
df$CODGEO <- as.character(df$CODGEO)
df$DCLT <- as.character(df$DCLT)
df$L_DCLT <- as.character(df$L_DCLT)


results <- data.frame(matrix(ncol=2, nrow=0))
for (i in mesCommunes) { # Pour chaque identifiant de commune nouvelle
  dfdep <- subset(df, CODGEO == i) # On identifie les flux sortants (dont la commune i est l'origine)
  Departs <- sum(dfdep$NBFLUX_C09_ACTOCC15P) # La somme donne le nombre de départs
  dfarriv <- subset(df, DCLT == i) # On identifie les flux entrants (dont la commune i est la destination)
  Arrivees <- sum(dfarriv$NBFLUX_C09_ACTOCC15P) # La somme donne le nombre d'arrivées
  Volume <- Departs + Arrivees
  Solde <- Arrivees - Departs
  Attractivite <- Solde / Volume
  a <- c(i, Volume, Solde, Attractivite)
  results <- rbind(results,a, stringsAsFactors= FALSE) # Combiner les résultats, par lignes
  rm(a, dfarriv, dfdep, Arrivees, Departs, Solde, Attractivite) # Supprimer les objets créés
  
}
colnames (results) <- c("CODGEO", "Volume", "Solde", "IndiceAttractivite")

results <- merge (results, df2011, by = "CODGEO", all.x = TRUE)


write.table(results, "Archives/sorties_2011-2020/export_indice_attract.txt", sep="\t", row.names=FALSE) # 


IndiceAttract <- read.table("Archives/sorties_2011-2020/export_indice_attract.txt", sep="\t",
                       colClasses = "character", head = TRUE, stringsAsFactors = TRUE)


```


### || 7.8.2 Test pour commmunes fusionnantes
Regardons maintenant, dans la liste des communes avec lesquelles les communes fusionnantes échangent, qui a le plus gros indice d'attractivité (chef-lieu, autre commune fusionnante, une autre à l'extérieur) et lister cela comme info sur la commune nouvelle.

```{r Analyse indice attract en partant des Navettes totales, eval = FALSE}

# Import pour lancer rapidement les tests
load("Archives/data_2011-2020/refdata.Rdata")
rm(df2020)
df2011 <- df2011[, c("LIBGEO_2020", "CODGEO_2020", "LIBGEO", "CODGEO", "ChefLieu", "CATAEU2010", "FusPhas", "COM_NOUV", "FUSION", "P09_POP", "REG")]
datafus2011 <- subset(df2011, COM_NOUV == "OUI") # Désigne les données concernant les communes ayant participé à la création d'une commune nouvelle, appelées ici communes fusionnantes


IndiceAttract <- read.table("Archives/sorties_2011-2020/export_indice_attract.txt", sep="\t",
                       colClasses = "character", head = TRUE, stringsAsFactors = TRUE)
IndiceAttract <- merge(IndiceAttract, datafus2011[, c("CODGEO", "CODGEO_2020")], by = "CODGEO", all.x = TRUE)
IndiceAttract$CODGEO_2020 <- as.character(IndiceAttract$CODGEO_2020)
IndiceAttract$CODGEO_2020[is.na(IndiceAttract$CODGEO_2020)] <- "NON"


NavettesToutes <- read.csv2("data-raw/Flux_domicile_travail/BTT_FM_DTR_2009.txt", stringsAsFactors=TRUE)
df <- NavettesToutes
# Création d'un champs indiquant si la commune origine appartient à une commune nouvelle
df <- merge(df, datafus2011[, c("CODGEO", "CODGEO_2020")], by = "CODGEO", all.x = TRUE)
# Adaptation des données au package flows
df$CODGEO <- as.character(df$CODGEO)
df$DCLT <- as.character(df$DCLT)
df$L_DCLT <- as.character(df$L_DCLT)
rm(NavettesToutes, geomfus2011) # Supprimer les objets pour alléger R


# Définition d'un vecteur comportant les identifiants des communes nouvelles à tester
datafus2011$CODGEO_2020 <- as.character(datafus2011$CODGEO_2020)
mesCommunes <- unique(datafus2011$CODGEO_2020)
mesCommunes <- as.character(mesCommunes)

results <-  data.frame() # On prépare le tableau avec les résultats

for (i in mesCommunes) { # Pour chaque identifiant de commune nouvelle, 
  nav1 <- subset (df, CODGEO_2020 == i) # Ne garder que navettes partant ou arrivant des communes fusionnantes y ayant participé
  # Ligne facultative :
  nav1 <- subset (nav1, NBFLUX_C09_ACTOCC15P >= (0.05 * max(nav1$NBFLUX_C09_ACTOCC15P))) # On ne conserve que les navettes qui font au moins 05% du flux maximum 
  nav1 <- nav1[order(-nav1$NBFLUX_C09_ACTOCC15P),] # On trie les flux par ordre décroissant
  # nav1 <- nav1[1:5,] # On ne conserve que les cinq premiers flux
  # nav1 <- nav1[1:10,] # On ne conserve que les dix premiers flux
  listeCommunes <- c(unique(nav1$DCLT), unique(nav1$CODGEO)) # On repère les codes des communes concernées
  listeCommunes <- unique(listeCommunes) # On retire les doubles comptes
  Pranalyse <- subset(IndiceAttract, CODGEO %in% listeCommunes) # On extrait les données synthétisées pour les communes concernées (peut induire quelques pertes, par exemple pour les navettes où la destination n'est pas connue, notée ZZZ)
  a <- ifelse(Pranalyse$CODGEO_2020[which.max(Pranalyse$Volume)] == i, "DsCN", "HorsCN") # On regarde si le maximum de volume est dans la commune nouvelle considérée
  a <- ifelse(Pranalyse$CODGEO[which.max(Pranalyse$Volume)] == i, "ChefLieu", a) # On regarde si le maximum est celui de la commune chef-lieu
  
  b <- ifelse(Pranalyse$CODGEO_2020[which.max(Pranalyse$Solde)] == i, "DsCN", "HorsCN") # On regarde si le maximum de solde est dans la commune nouvelle considérée
  b <- ifelse(Pranalyse$CODGEO[which.max(Pranalyse$Solde)] == i, "ChefLieu", b) # On regarde si le maximum est celui de la commune chef-lieu

  c <- ifelse(Pranalyse$CODGEO_2020[which.max(Pranalyse$IndiceAttractivite)] == i, "DsCN", "HorsCN") # On regarde si le maximum d'attractivité est dans la commune nouvelle considérée
  c <- ifelse(Pranalyse$CODGEO[which.max(Pranalyse$IndiceAttractivite)] == i, "ChefLieu", c) # On regarde si le maximum est celui de la commune chef-lieu

  resultspartiels <- c(i, a, b, c)
  results <- rbind(results,resultspartiels, stringsAsFactors= FALSE) # Combiner les résultats, par lignes
  
  rm(nav1, listeCommunes, Pranalyse, a, b, c, resultspartiels)
  
}
colnames(results) <- c("CODGEO_2020", "MaxVolume", "MaxSolde", "MaxAttract")

write.table(results, "Archives/sorties_2011-2020/export_tests_sur_Vol-Solde-Attract_flux_sup_05pct.txt", sep="\t", row.names=FALSE) 
```

### || 7.8.3 Sortie tableau 

Si on regarde l'ensemble des flux entrant ou sortant de communes fusionnantes appartenant à une même commune nouvelle, le tableau suivant donne le nombre de fois où les volumes, soldes et attractivités les plus importants sont le chef-lieu de la commune nouvelle, une autre commune fusionnante, ou hors de la commune nouvelle.

```{r Analyse indice attract, eval = TRUE}
results <- read.table("Archives/sorties_2011-2020/export_tests_sur_Vol-Solde-Attract_flux_sup_05pct.txt", sep="\t",
colClasses = c("character", "factor", "factor", "factor"), head = TRUE, stringsAsFactors = TRUE)

a <-summary (results$MaxVolume)
a <-c(sum(results$MaxVolume == "ChefLieu"), sum(results$MaxVolume == "DsCN"), sum(results$MaxVolume == "HorsCN")) # Nécessaire car présence d'un zéro
b <- summary(results$MaxSolde)
c <- summary(results$MaxAttract)
tableau <- rbind (a, b, c)
rm(a, b, c)
row.names(tableau) <- c("La commune avec le plus grand volume est", "La commune avec le plus grand solde est", "La commune avec la plus grande attractivité est")
colnames(tableau) <- c("Le chef-lieu de la commune nouvelle", "Une autre commune de la même commune nouvelle", "Hors de la commune nouvelle")
kable(tableau, caption = "Les pôles migratoires des communes fusionnantes")


```

On y observe que, très majoritairement, les communes nouvelles sont constituées par des communes qui ne polarisent pas leur environnement. En revanche, lorsque ces éléments sont dans les communes nouvelles, ils sont très largement le fait des communes devenues chef-lieu, ce qui paraît, de manière assez cohérente, aller dans une logique de centralisation.


```{r Les CN avec max en intérieur, eval = FALSE}

# On s'intéresse aux communes qui sont avec un pôle important à l'intérieur de la commune nouvelle
extraitsresults <- subset (results, MaxVolume == "DsCN" | MaxSolde== "DsCN" | MaxAttract == "DsCN"
                           | MaxVolume == "ChefLieu" | MaxSolde== "ChefLieu" | MaxAttract == "ChefLieu")
ComNvlles <- subset (datafus2011, ChefLieu == "O")
colnames(results)[1] <- "CODGEO_2020"
extraitsresults <- merge (extraitsresults, ComNvlles[, c("CODGEO_2020", "LIBGEO_2020", "CATAEU2010")], by = "CODGEO_2020")

summary(extraitsresults$CATAEU2010)
tabcont <- table(extraitsresults$MaxVolume, extraitsresults$CATAEU2010)
table(extraitsresults$MaxSolde, extraitsresults$CATAEU2010)
tabcont <- table(extraitsresults$MaxAttract, extraitsresults$CATAEU2010)
prop <- prop.table(tabcont) * 100
barplot(prop, main= NULL,
        xlab = "Catégories d'aire urbaine de la commune chef-lieu de la commune nouvelle",
        ylab = "Part du total des communes (%)",
        las = 2,
        border = NA,
        col= terrain.colors(nrow(prop)),
        beside = TRUE)

legend(x="topright", legend = rownames(prop) , cex=0.8, fill = terrain.colors(nrow(prop)), bty="n", title = "La commune ayant le plus grand indice d'attractivité est :")     

```


```{r Nettoyage espace de travail fin section 7, echo = FALSE}
rm(list=ls())
```


# 99 - ANNEXES
## 99.1 - Le Zonage en Aires Urbaines

Source : INSEE

Catégorie de la commune dans le zonage en aires urbaines 2010
Ce code indique la catégorie de la commune au sein du découpage en aires urbaines.

Modalités :

111 : Commune appartenant à un grand pôle (10 000 emplois ou plus)
112 : Commune appartenant à la couronne d'un grand pôle
120 : Commune multipolarisée des grandes aires urbaines
211 : Commune appartenant à un moyen pôle (5 000 à moins de 10 000 emplois)
212 : Commune appartenant à la couronne d'un moyen pôle
221 : Commune appartenant à un petit pôle (de 1 500 à moins de 5 000 emplois)
222 : Commune appartenant à la couronne d'un petit pôle
300 : Autre commune multipolarisée
400 : Commune isolée hors influence des pôles

L'espace des grandes aires urbaines est composé des communes dont la modalité vaut 111, 112, ou 120.
L'espace des autres aires urbaines et composé des communes dont la modalité vaut 211, 212, 221 ou 222.

Par ailleurs, l'espace péri-urbain est composé des communes dont la modalité vaut 112 ou 120.

## 99.2 Cartographie en fonction de la superficie moyenne des communes
Ci-dessous, une carte permettant de noter que la répartition des communes nouvelles ne paraît pas liée à la superficie moyenne des communes françaises
```{r Superficie moyenne communes et CN}
geom2011 <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "geom2011", quiet = TRUE)
dep <- st_read("Archives/data_2011-2020/geom.gpkg", layer = "dep", quiet = TRUE)
load("Archives/data_2011-2020/refdata.Rdata")
datafus2011 <- subset(df2011, COM_NOUV == "OUI")
dataCN_2020 <- subset(df2020, COM_NOUV == "OUI")

df2011$surface <- st_area(geom2011) # Attention, unités : m²
df2011$surface <- set_units(df2011$surface, km^2) # On passe en km²

FusionsDep<-data.frame(table(df2011$CODE_DEPT))
colnames(FusionsDep)<-c("CODE_DEPT", "NbrCom")
NbrComFusDep <- data.frame(table(datafus2011$CODE_DEPT))
colnames(NbrComFusDep)<-c("CODE_DEPT", "NbrComFus")
FusionsDep <- merge(FusionsDep, NbrComFusDep, by = "CODE_DEPT", all = TRUE)
FusionsDep$SurfaceMoy <- tapply (df2011$surface, df2011$CODE_DEPT, mean)

ShpDep <- as(dep, "Spatial")


# pdf("Communes nouvelles et densité de communes (2012-2020).pdf")
svg("figures/Communes nouvelles et superficie moyenne des communes (2012-2020).svg")
# Carte départementale sur superficie moyenne des communes et nombre de fusions
plot(ShpDep, col = "grey", border = "white", axes = FALSE) # Fond de carte
# Carte choroplèthe en fonction de la superficie moyenne des communes dans le département
choroLayer(spdf = ShpDep, # SpatialPolygonsDataFrame
           df = FusionsDep, # data frame
           spdfid = "CODE_DEPT",
           dfid = "CODE_DEPT",
           var = "SurfaceMoy",
           # Si on souhaite faire les groupes manuellement :
           # breaks = c(0,0.27,5,10, 37), # liste des seuils (hypothèses)
           # col = carto.pal(pal1 = "turquoise.pal", n1 = 6, pal2 = "blue.pal", n2 = 0),
           # Si on souhaite avoir des groupes par quantiles :
           col = carto.pal(pal1 = "red.pal", n1 = 4), method = "quantile",
           nclass = 4,
           add=TRUE,
           legend.pos = "topleft", 
           legend.title.txt = "Superficie moyenne des communes (km²)")
# On rajoute les cercles en fonction du nombre de communes ayant fusionné
propSymbolsLayer(spdf = ShpDep, # Ou à la place on peut utiliser "spdf = Communesfus" créé plus haut
                 df = FusionsDep,
                 spdfid = "CODE_DEPT",
                 dfid = "CODE_DEPT",
                 var = "NbrComFus",
                 inches = 0.2,
                 #breakval = 3, # On précise une valeur tournant
                 symbols = "circle",
                 col = "blue",
                 #col2 = "red",
                 legend.pos = "left",
                 legend.title.txt = "\n\n\n\n\nNombre de\ncommunes\nayant participé à la\ncréation d'une\ncommune nouvelle",
                 legend.style = "e",
                 legend.frame = FALSE,
                 add = TRUE)
layoutLayer(title = "Communes nouvelles et superficie moyenne des communes (2012-2020)", coltitle = "black",
            sources = "Sources : INSEE, IGN, 2020.", scale = NULL,
            author = "G. Bideau, R. Ysebaert", frame ="", col = NA)
dev.off()

```


```{r Nettoyage espace de travail fin section 9, echo = FALSE}
rm(list=ls())
```


# Bibliographie
\nocite{}

